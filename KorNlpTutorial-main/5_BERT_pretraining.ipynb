{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "5_BERT_pretraining.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BY9BrKNmxY21"
      },
      "source": [
        "# BERT 학습을 위한 vocab을 만들기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oDOWsss0xfvU"
      },
      "source": [
        "학습에 사용될 vocab을 만들어보겠습니다.\n",
        "\n",
        "아래 코드를 실행하시면, vocab을 만들 수 있습니다.\n",
        "\n",
        "이번 예제에서는 결과를 빠르게 확인하기 위해 iter를 20으로 두었으나, \n",
        "\n",
        "wiki를 기준으로 1000 정도로 iter를 설정하면 대략 30,000 vocab정도 만들어집니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5niMDu3tTgBV",
        "outputId": "4db626de-21d2-4bda-e9af-691bd6c8c98a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%tensorflow_version 1.x"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BkAf3KkFRJeb",
        "outputId": "d15f4348-a02a-4597-c0a0-7ae350972ac5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "!git clone https://github.com/google-research/bert.git"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'bert'...\n",
            "remote: Enumerating objects: 340, done.\u001b[K\n",
            "remote: Total 340 (delta 0), reused 0 (delta 0), pack-reused 340\u001b[K\n",
            "Receiving objects: 100% (340/340), 317.85 KiB | 12.22 MiB/s, done.\n",
            "Resolving deltas: 100% (185/185), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cI3oe7--RMI6",
        "outputId": "cedc69c4-10fc-419c-df72-029f9a6cf32a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "!git clone https://github.com/MrBananaHuman/WordPieceTokenizer.git"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'WordPieceTokenizer'...\n",
            "remote: Enumerating objects: 9, done.\u001b[K\n",
            "remote: Counting objects: 100% (9/9), done.\u001b[K\n",
            "remote: Compressing objects: 100% (8/8), done.\u001b[K\n",
            "remote: Total 9 (delta 1), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (9/9), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0zhYEYjVTBAk",
        "outputId": "2ba1f513-e35e-45a9-df02-68696e1e6452",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "!curl -c ./cookie -s -L \"https://drive.google.com/uc?export=download&id=1CQT4Sear6NKxGiZIW3WpAGkTanO0azrl\" > /dev/null\n",
        "!curl -Lb ./cookie \"https://drive.google.com/uc?export=download&confirm=`awk '/download/ {print $NF}' ./cookie`&id=1CQT4Sear6NKxGiZIW3WpAGkTanO0azrl\" -o wiki_20190620_small.txt"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100   408    0   408    0     0   2158      0 --:--:-- --:--:-- --:--:--  2158\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "100 40965  100 40965    0     0  86060      0 --:--:-- --:--:-- --:--:--     0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZCqqzd2Ox2ih",
        "outputId": "01dabd55-6d98-4e2f-bd95-3267fddee037",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 422
        }
      },
      "source": [
        "!python /content/WordPieceTokenizer/wordpiece.py \\\n",
        "--corpus=/content/wiki_20190620_small.txt \\\n",
        "--iter=20 \\\n",
        "--fname=my_vocab.txt"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "begin vocabulary scanning\rterminated vocabulary scanning\n",
            "('##다', '##.')\n",
            "('##으', '##로')\n",
            "('##에', '##서')\n",
            "('##하', '##는')\n",
            "('있', '##다.')\n",
            "('##이', '##다.')\n",
            "('화', '##학')\n",
            "('수', '##학')\n",
            "('1', '##9')\n",
            "('##적', '##인')\n",
            "('##한', '##다.')\n",
            "('대', '##한')\n",
            "('##고', '##,')\n",
            "('원', '##자')\n",
            "('##었', '##다.')\n",
            "('원', '##소')\n",
            "('##합', '##물')\n",
            "('##하', '##여')\n",
            "('다', '##루')\n",
            "('물', '##질')\n",
            "('연', '##구')\n",
            "training bpe was done                                        \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vyv47UR0SIdd"
      },
      "source": [
        "#BERT 학습을 위한 Preprocessed data 만들기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f_UcTWFhSPHS"
      },
      "source": [
        "이제 vocab 이 준비되었으니, BERT 학습을 위한 corpus를 preprocessing 해보도록 하겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fM6i3hylSl24",
        "outputId": "ce9b0539-f36c-49a9-c7bc-d8616bd41e31",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!python /content/bert/create_pretraining_data.py \\\n",
        "--input_file=/content/wiki_20190620_small.txt \\\n",
        "--vocab_file=/content/my_vocab.txt \\\n",
        "--do_lower_case=False \\\n",
        "--max_seq_length=64 \\\n",
        "--output_file=/content/wiki_20190620_small_64_tf.record"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /content/bert/create_pretraining_data.py:469: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/bert/create_pretraining_data.py:437: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.\n",
            "\n",
            "W1019 15:03:31.652317 140518079915904 module_wrapper.py:139] From /content/bert/create_pretraining_data.py:437: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/bert/create_pretraining_data.py:437: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.\n",
            "\n",
            "W1019 15:03:31.652624 140518079915904 module_wrapper.py:139] From /content/bert/create_pretraining_data.py:437: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/bert/tokenization.py:125: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "W1019 15:03:31.652966 140518079915904 module_wrapper.py:139] From /content/bert/tokenization.py:125: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/bert/create_pretraining_data.py:444: The name tf.gfile.Glob is deprecated. Please use tf.io.gfile.glob instead.\n",
            "\n",
            "W1019 15:03:31.656509 140518079915904 module_wrapper.py:139] From /content/bert/create_pretraining_data.py:444: The name tf.gfile.Glob is deprecated. Please use tf.io.gfile.glob instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/bert/create_pretraining_data.py:446: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
            "\n",
            "W1019 15:03:31.657794 140518079915904 module_wrapper.py:139] From /content/bert/create_pretraining_data.py:446: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
            "\n",
            "INFO:tensorflow:*** Reading from input files ***\n",
            "I1019 15:03:31.657967 140518079915904 create_pretraining_data.py:446] *** Reading from input files ***\n",
            "INFO:tensorflow:  /content/wiki_20190620_small.txt\n",
            "I1019 15:03:31.658119 140518079915904 create_pretraining_data.py:448]   /content/wiki_20190620_small.txt\n",
            "INFO:tensorflow:*** Writing to output files ***\n",
            "I1019 15:03:32.364963 140518079915904 create_pretraining_data.py:457] *** Writing to output files ***\n",
            "INFO:tensorflow:  /content/wiki_20190620_small_64_tf.record\n",
            "I1019 15:03:32.365221 140518079915904 create_pretraining_data.py:459]   /content/wiki_20190620_small_64_tf.record\n",
            "WARNING:tensorflow:From /content/bert/create_pretraining_data.py:101: The name tf.python_io.TFRecordWriter is deprecated. Please use tf.io.TFRecordWriter instead.\n",
            "\n",
            "W1019 15:03:32.365548 140518079915904 module_wrapper.py:139] From /content/bert/create_pretraining_data.py:101: The name tf.python_io.TFRecordWriter is deprecated. Please use tf.io.TFRecordWriter instead.\n",
            "\n",
            "INFO:tensorflow:*** Example ***\n",
            "I1019 15:03:32.366289 140518079915904 create_pretraining_data.py:149] *** Example ***\n",
            "INFO:tensorflow:tokens: [CLS] ##활 ##에 필 ##수 [MASK] [MASK] ##문 [MASK] ##측 ##과 달 ##력 ##의 제 ##정 약 토 ##지 ##의 측 ##량 또 ##한 수학 ##이 [MASK] ##접 ##적 [MASK] 관 ##여 ##한 분 ##야 ##이 [SEP] 플 ##라 ##스 ##틱 [MASK] 합 ##성 ##섬 ##유 ##등 ##의 고 ##분 ##자 ##물질 등 ##도 유 ##기 ##화학 ##에서 다루 ##어 ##진 [MASK] [UNK] [SEP]\n",
            "I1019 15:03:32.366520 140518079915904 create_pretraining_data.py:151] tokens: [CLS] ##활 ##에 필 ##수 [MASK] [MASK] ##문 [MASK] ##측 ##과 달 ##력 ##의 제 ##정 약 토 ##지 ##의 측 ##량 또 ##한 수학 ##이 [MASK] ##접 ##적 [MASK] 관 ##여 ##한 분 ##야 ##이 [SEP] 플 ##라 ##스 ##틱 [MASK] 합 ##성 ##섬 ##유 ##등 ##의 고 ##분 ##자 ##물질 등 ##도 유 ##기 ##화학 ##에서 다루 ##어 ##진 [MASK] [UNK] [SEP]\n",
            "INFO:tensorflow:input_ids: 0 516 10 545 39 4 4 69 4 299 21 440 292 5 141 40 370 659 17 5 340 250 104 14 70 9 4 459 36 4 128 217 14 35 93 9 3 637 46 45 832 4 408 37 833 215 421 5 144 89 28 565 81 26 76 13 92 30 133 23 152 4 2 3\n",
            "I1019 15:03:32.366727 140518079915904 create_pretraining_data.py:161] input_ids: 0 516 10 545 39 4 4 69 4 299 21 440 292 5 141 40 370 659 17 5 340 250 104 14 70 9 4 459 36 4 128 217 14 35 93 9 3 637 46 45 832 4 408 37 833 215 421 5 144 89 28 565 81 26 76 13 92 30 133 23 152 4 2 3\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I1019 15:03:32.366899 140518079915904 create_pretraining_data.py:161] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I1019 15:03:32.367065 140518079915904 create_pretraining_data.py:161] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:masked_lm_positions: 5 6 8 9 16 26 29 41 44 61 0 0 0 0 0 0 0 0 0 0\n",
            "I1019 15:03:32.367206 140518079915904 create_pretraining_data.py:161] masked_lm_positions: 5 6 8 9 16 26 29 41 44 61 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_ids: 96 403 128 299 696 540 24 696 833 109 0 0 0 0 0 0 0 0 0 0\n",
            "I1019 15:03:32.367411 140518079915904 create_pretraining_data.py:161] masked_lm_ids: 96 403 128 299 696 540 24 696 833 109 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
            "I1019 15:03:32.367614 140518079915904 create_pretraining_data.py:161] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
            "INFO:tensorflow:next_sentence_labels: 1\n",
            "I1019 15:03:32.367754 140518079915904 create_pretraining_data.py:161] next_sentence_labels: 1\n",
            "INFO:tensorflow:*** Example ***\n",
            "I1019 15:03:32.368727 140518079915904 create_pretraining_data.py:149] *** Example ***\n",
            "INFO:tensorflow:tokens: [CLS] 갈 ##등 [MASK] 보 ##이 ##기 ##도 했 ##지 ##만 , 전 [MASK] 대 ##통 ##령 ##의 권 ##한 ##과 [MASK] ##야 유 ##명 인 ##사 [MASK] ##의 활 ##약 ##으로 [SEP] 실 ##험 ##을 호 ##소 ##했 [MASK] ##며 실 ##험 ##은 [MASK] ##니 , 화 ##염 , [MASK] ##기 및 물 ##과 같 ##은 고 ##전 [MASK] 4 [MASK] ##지 [SEP]\n",
            "I1019 15:03:32.368983 140518079915904 create_pretraining_data.py:151] tokens: [CLS] 갈 ##등 [MASK] 보 ##이 ##기 ##도 했 ##지 ##만 , 전 [MASK] 대 ##통 ##령 ##의 권 ##한 ##과 [MASK] ##야 유 ##명 인 ##사 [MASK] ##의 활 ##약 ##으로 [SEP] 실 ##험 ##을 호 ##소 ##했 [MASK] ##며 실 ##험 ##은 [MASK] ##니 , 화 ##염 , [MASK] ##기 및 물 ##과 같 ##은 고 ##전 [MASK] 4 [MASK] ##지 [SEP]\n",
            "INFO:tensorflow:input_ids: 0 650 421 4 95 9 13 26 393 17 147 696 72 4 32 174 198 5 869 14 21 4 93 76 146 56 78 4 5 396 320 24 3 166 305 8 687 75 98 4 77 166 305 11 4 317 696 135 465 696 4 13 193 124 21 208 11 144 65 4 400 4 17 3\n",
            "I1019 15:03:32.369246 140518079915904 create_pretraining_data.py:161] input_ids: 0 650 421 4 95 9 13 26 393 17 147 696 72 4 32 174 198 5 869 14 21 4 93 76 146 56 78 4 5 396 320 24 3 166 305 8 687 75 98 4 77 166 305 11 4 317 696 135 465 696 4 13 193 124 21 208 11 144 65 4 400 4 17 3\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I1019 15:03:32.369423 140518079915904 create_pretraining_data.py:161] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I1019 15:03:32.369642 140518079915904 create_pretraining_data.py:161] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:masked_lm_positions: 3 13 21 27 39 44 45 50 59 61 0 0 0 0 0 0 0 0 0 0\n",
            "I1019 15:03:32.369812 140518079915904 create_pretraining_data.py:161] masked_lm_positions: 3 13 21 27 39 44 45 50 59 61 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_ids: 8 352 287 33 114 142 103 79 96 82 0 0 0 0 0 0 0 0 0 0\n",
            "I1019 15:03:32.369946 140518079915904 create_pretraining_data.py:161] masked_lm_ids: 8 352 287 33 114 142 103 79 96 82 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
            "I1019 15:03:32.370101 140518079915904 create_pretraining_data.py:161] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
            "INFO:tensorflow:next_sentence_labels: 1\n",
            "I1019 15:03:32.370271 140518079915904 create_pretraining_data.py:161] next_sentence_labels: 1\n",
            "INFO:tensorflow:*** Example ***\n",
            "I1019 15:03:32.370666 140518079915904 create_pretraining_data.py:149] *** Example ***\n",
            "INFO:tensorflow:tokens: [CLS] 상 ##업 ##성 ##을 띠 ##며 대 ##중 ##을 겨 ##냥 [MASK] 그 [MASK] ##의 통 ##속 ##적인 [MASK] 서 ##와 욕 ##구 ##를 채 [MASK] ##주 [MASK] 문 ##학 ##을 [SEP] 하 ##위 ##장 ##르 ##에 [MASK] 여 ##러 ##가 ##지 ##가 있 ##다 [UNK] 문 ##학 ##을 [MASK] ##작 [MASK] 예 ##술 ##가 [MASK] 문 ##예 ##가 ##라 ##고 부 [SEP]\n",
            "I1019 15:03:32.370852 140518079915904 create_pretraining_data.py:151] tokens: [CLS] 상 ##업 ##성 ##을 띠 ##며 대 ##중 ##을 겨 ##냥 [MASK] 그 [MASK] ##의 통 ##속 ##적인 [MASK] 서 ##와 욕 ##구 ##를 채 [MASK] ##주 [MASK] 문 ##학 ##을 [SEP] 하 ##위 ##장 ##르 ##에 [MASK] 여 ##러 ##가 ##지 ##가 있 ##다 [UNK] 문 ##학 ##을 [MASK] ##작 [MASK] 예 ##술 ##가 [MASK] 문 ##예 ##가 ##라 ##고 부 [SEP]\n",
            "INFO:tensorflow:input_ids: 0 149 345 37 8 489 77 32 304 8 913 790 4 38 4 5 316 153 96 4 260 57 914 103 16 651 4 130 4 67 22 8 3 101 120 157 148 10 4 258 121 20 17 20 60 109 2 67 22 8 4 249 4 183 181 20 4 67 357 20 46 25 189 3\n",
            "I1019 15:03:32.371038 140518079915904 create_pretraining_data.py:161] input_ids: 0 149 345 37 8 489 77 32 304 8 913 790 4 38 4 5 316 153 96 4 260 57 914 103 16 651 4 130 4 67 22 8 3 101 120 157 148 10 4 258 121 20 17 20 60 109 2 67 22 8 4 249 4 183 181 20 4 67 357 20 46 25 189 3\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I1019 15:03:32.371208 140518079915904 create_pretraining_data.py:161] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I1019 15:03:32.371376 140518079915904 create_pretraining_data.py:161] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:masked_lm_positions: 12 14 19 20 26 28 38 50 52 56 0 0 0 0 0 0 0 0 0 0\n",
            "I1019 15:03:32.371535 140518079915904 create_pretraining_data.py:161] masked_lm_positions: 12 14 19 20 26 28 38 50 52 56 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_ids: 129 33 679 145 452 6 6 365 43 16 0 0 0 0 0 0 0 0 0 0\n",
            "I1019 15:03:32.371679 140518079915904 create_pretraining_data.py:161] masked_lm_ids: 129 33 679 145 452 6 6 365 43 16 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
            "I1019 15:03:32.371825 140518079915904 create_pretraining_data.py:161] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
            "INFO:tensorflow:next_sentence_labels: 0\n",
            "I1019 15:03:32.371962 140518079915904 create_pretraining_data.py:161] next_sentence_labels: 0\n",
            "INFO:tensorflow:*** Example ***\n",
            "I1019 15:03:32.372311 140518079915904 create_pretraining_data.py:149] *** Example ***\n",
            "INFO:tensorflow:tokens: [CLS] [MASK] 화학 ##적 현 ##상 ##에 대한 해 ##석 ##과 [MASK] [MASK] 설 ##명 ##하 ##기 위 ##한 [MASK] ##리 ##적 원 ##리 ##들 ##에 대 ##해 다루 ##는 분 ##과 [SEP] ( [UNK] ) [MASK] 일 ##반 ##적인 화학 [MASK] , 물 [MASK] ##학 ##적 방 ##법 ##으로 ##는 분 ##해 ##되 ##지 않 ##는 물질 ##을 [MASK] ##미 ##한 ##다 [SEP]\n",
            "I1019 15:03:32.372514 140518079915904 create_pretraining_data.py:151] tokens: [CLS] [MASK] 화학 ##적 현 ##상 ##에 대한 해 ##석 ##과 [MASK] [MASK] 설 ##명 ##하 ##기 위 ##한 [MASK] ##리 ##적 원 ##리 ##들 ##에 대 ##해 다루 ##는 분 ##과 [SEP] ( [UNK] ) [MASK] 일 ##반 ##적인 화학 [MASK] , 물 [MASK] ##학 ##적 방 ##법 ##으로 ##는 분 ##해 ##되 ##지 않 ##는 물질 ##을 [MASK] ##미 ##한 ##다 [SEP]\n",
            "INFO:tensorflow:input_ids: 0 4 55 36 185 53 10 110 188 118 21 4 4 312 146 18 13 111 14 4 27 36 336 27 33 10 32 31 133 6 35 21 3 334 2 388 4 80 151 96 55 4 696 124 4 22 36 86 132 24 6 35 31 34 17 210 6 134 8 4 145 14 109 3\n",
            "I1019 15:03:32.372711 140518079915904 create_pretraining_data.py:161] input_ids: 0 4 55 36 185 53 10 110 188 118 21 4 4 312 146 18 13 111 14 4 27 36 336 27 33 10 32 31 133 6 35 21 3 334 2 388 4 80 151 96 55 4 696 124 4 22 36 86 132 24 6 35 31 34 17 210 6 134 8 4 145 14 109 3\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I1019 15:03:32.372879 140518079915904 create_pretraining_data.py:161] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I1019 15:03:32.373068 140518079915904 create_pretraining_data.py:161] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:masked_lm_positions: 1 11 12 19 36 41 44 47 58 59 0 0 0 0 0 0 0 0 0 0\n",
            "I1019 15:03:32.373206 140518079915904 create_pretraining_data.py:161] masked_lm_positions: 1 11 12 19 36 41 44 47 58 59 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_ids: 11 12 16 124 2 36 27 86 8 143 0 0 0 0 0 0 0 0 0 0\n",
            "I1019 15:03:32.373353 140518079915904 create_pretraining_data.py:161] masked_lm_ids: 11 12 16 124 2 36 27 86 8 143 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
            "I1019 15:03:32.373515 140518079915904 create_pretraining_data.py:161] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
            "INFO:tensorflow:next_sentence_labels: 1\n",
            "I1019 15:03:32.373648 140518079915904 create_pretraining_data.py:161] next_sentence_labels: 1\n",
            "INFO:tensorflow:*** Example ***\n",
            "I1019 15:03:32.374010 140518079915904 create_pretraining_data.py:149] *** Example ***\n",
            "INFO:tensorflow:tokens: [CLS] ##은 형 ##식 논 ##리 ##를 이 ##용 ##해 ##서 공 ##리 ##로 구 ##성 ##된 [MASK] ##상 ##적 [MASK] ##조 ##를 연구 ##하는 학 ##문 [MASK] 여 [MASK] ##지 ##기 ##도 [SEP] [MASK] ##부 [MASK] 러 ##시 [MASK] ##인 , 인 ##구 ##시 ##인 ##과 [MASK] ##타 북 ##코 ##카 ##서 ##스 [MASK] 민 ##족 ##도 섞 ##여 ##있 ##다 [UNK] [SEP]\n",
            "I1019 15:03:32.374175 140518079915904 create_pretraining_data.py:151] tokens: [CLS] ##은 형 ##식 논 ##리 ##를 이 ##용 ##해 ##서 공 ##리 ##로 구 ##성 ##된 [MASK] ##상 ##적 [MASK] ##조 ##를 연구 ##하는 학 ##문 [MASK] 여 [MASK] ##지 ##기 ##도 [SEP] [MASK] ##부 [MASK] 러 ##시 [MASK] ##인 , 인 ##구 ##시 ##인 ##과 [MASK] ##타 북 ##코 ##카 ##서 ##스 [MASK] 민 ##족 ##도 섞 ##여 ##있 ##다 [UNK] [SEP]\n",
            "INFO:tensorflow:input_ids: 0 11 239 122 234 27 16 12 88 31 41 79 27 19 83 37 73 4 53 36 4 213 16 140 43 314 69 4 258 4 17 13 26 3 4 64 4 276 54 4 63 696 56 103 54 63 21 4 164 288 633 462 41 45 4 360 358 26 957 217 427 109 2 3\n",
            "I1019 15:03:32.374370 140518079915904 create_pretraining_data.py:161] input_ids: 0 11 239 122 234 27 16 12 88 31 41 79 27 19 83 37 73 4 53 36 4 213 16 140 43 314 69 4 258 4 17 13 26 3 4 64 4 276 54 4 63 696 56 103 54 63 21 4 164 288 633 462 41 45 4 360 358 26 957 217 427 109 2 3\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I1019 15:03:32.374595 140518079915904 create_pretraining_data.py:161] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I1019 15:03:32.374766 140518079915904 create_pretraining_data.py:161] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:masked_lm_positions: 17 20 27 29 34 36 39 47 48 54 0 0 0 0 0 0 0 0 0 0\n",
            "I1019 15:03:32.374918 140518079915904 create_pretraining_data.py:161] masked_lm_positions: 17 20 27 29 34 36 39 47 48 54 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_ids: 225 83 24 730 80 6 97 52 164 94 0 0 0 0 0 0 0 0 0 0\n",
            "I1019 15:03:32.375059 140518079915904 create_pretraining_data.py:161] masked_lm_ids: 225 83 24 730 80 6 97 52 164 94 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
            "I1019 15:03:32.375203 140518079915904 create_pretraining_data.py:161] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
            "INFO:tensorflow:next_sentence_labels: 1\n",
            "I1019 15:03:32.375334 140518079915904 create_pretraining_data.py:161] next_sentence_labels: 1\n",
            "INFO:tensorflow:*** Example ***\n",
            "I1019 15:03:32.375687 140518079915904 create_pretraining_data.py:149] *** Example ***\n",
            "INFO:tensorflow:tokens: [CLS] 이 ##상 나 [MASK] ##지 않 ##는 [MASK] ##초 ##적인 요 ##소 ##가 [MASK] ##재 ##한 ##널 ##고 했 ##는 ##데 , 이 [MASK] ##초 ##적인 요 [MASK] ##를 원자 ( [SEP] [MASK] ##을 쉽 ##게 하 ##는 것 ##과 , 마 ##찬 ##가 ##지 ##로 수학 르 법 ##런 ##을 일 ##반 ##적 ##이 [MASK] 간 ##명 ##하 ##게 나 ##타 [SEP]\n",
            "I1019 15:03:32.375855 140518079915904 create_pretraining_data.py:151] tokens: [CLS] 이 ##상 나 [MASK] ##지 않 ##는 [MASK] ##초 ##적인 요 ##소 ##가 [MASK] ##재 ##한 ##널 ##고 했 ##는 ##데 , 이 [MASK] ##초 ##적인 요 [MASK] ##를 원자 ( [SEP] [MASK] ##을 쉽 ##게 하 ##는 것 ##과 , 마 ##찬 ##가 ##지 ##로 수학 르 법 ##런 ##을 일 ##반 ##적 ##이 [MASK] 간 ##명 ##하 ##게 나 ##타 [SEP]\n",
            "INFO:tensorflow:input_ids: 0 12 53 91 4 17 210 6 4 267 96 448 75 20 4 137 14 707 25 393 6 163 696 12 4 267 96 448 4 16 115 334 3 4 8 889 87 101 6 68 21 696 389 519 20 17 19 70 873 342 381 8 80 151 36 9 4 363 146 18 87 91 164 3\n",
            "I1019 15:03:32.376036 140518079915904 create_pretraining_data.py:161] input_ids: 0 12 53 91 4 17 210 6 4 267 96 448 75 20 4 137 14 707 25 393 6 163 696 12 4 267 96 448 4 16 115 334 3 4 8 889 87 101 6 68 21 696 389 519 20 17 19 70 873 342 381 8 80 151 36 9 4 363 146 18 87 91 164 3\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I1019 15:03:32.376222 140518079915904 create_pretraining_data.py:161] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I1019 15:03:32.376400 140518079915904 create_pretraining_data.py:161] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:masked_lm_positions: 4 8 14 17 24 28 33 48 50 56 0 0 0 0 0 0 0 0 0 0\n",
            "I1019 15:03:32.376556 140518079915904 create_pretraining_data.py:161] masked_lm_positions: 4 8 14 17 24 28 33 48 50 56 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_ids: 616 52 257 109 52 75 204 36 302 25 0 0 0 0 0 0 0 0 0 0\n",
            "I1019 15:03:32.376698 140518079915904 create_pretraining_data.py:161] masked_lm_ids: 616 52 257 109 52 75 204 36 302 25 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
            "I1019 15:03:32.376841 140518079915904 create_pretraining_data.py:161] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
            "INFO:tensorflow:next_sentence_labels: 1\n",
            "I1019 15:03:32.376976 140518079915904 create_pretraining_data.py:161] next_sentence_labels: 1\n",
            "INFO:tensorflow:*** Example ***\n",
            "I1019 15:03:32.377359 140518079915904 create_pretraining_data.py:149] *** Example ***\n",
            "INFO:tensorflow:tokens: [CLS] 그 [MASK] [MASK] , 이 ##는 현 ##재 ##까 ##지 ##도 계 [MASK] [MASK] ##고 [MASK] ##다 [UNK] [SEP] [MASK] ##날 수학 ##은 자 ##연 ##과 ##학 , 공 ##학 , ##의 ##학 ##뿐 ##만 아 ##니 ##죄 [MASK] 경 ##제 ##학 등 ##의 사 ##회 ##과 ##학 ##에서 ##도 중 ##요 ##한 도 ##구 ##로 ##서 ##도 사 ##용 ##된 ##다 [SEP]\n",
            "I1019 15:03:32.377536 140518079915904 create_pretraining_data.py:151] tokens: [CLS] 그 [MASK] [MASK] , 이 ##는 현 ##재 ##까 ##지 ##도 계 [MASK] [MASK] ##고 [MASK] ##다 [UNK] [SEP] [MASK] ##날 수학 ##은 자 ##연 ##과 ##학 , 공 ##학 , ##의 ##학 ##뿐 ##만 아 ##니 ##죄 [MASK] 경 ##제 ##학 등 ##의 사 ##회 ##과 ##학 ##에서 ##도 중 ##요 ##한 도 ##구 ##로 ##서 ##도 사 ##용 ##된 ##다 [SEP]\n",
            "INFO:tensorflow:input_ids: 0 38 4 4 696 12 6 185 137 280 17 26 308 4 4 25 4 109 2 3 4 424 70 11 106 206 21 22 696 79 22 696 5 22 734 147 191 317 592 4 237 99 22 81 5 47 322 21 22 30 26 66 205 14 391 103 19 41 26 47 88 73 109 3\n",
            "I1019 15:03:32.377733 140518079915904 create_pretraining_data.py:161] input_ids: 0 38 4 4 696 12 6 185 137 280 17 26 308 4 4 25 4 109 2 3 4 424 70 11 106 206 21 22 696 79 22 696 5 22 734 147 191 317 592 4 237 99 22 81 5 47 322 21 22 30 26 66 205 14 391 103 19 41 26 47 88 73 109 3\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I1019 15:03:32.377900 140518079915904 create_pretraining_data.py:161] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I1019 15:03:32.378060 140518079915904 create_pretraining_data.py:161] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:masked_lm_positions: 2 3 13 14 16 20 26 32 38 39 0 0 0 0 0 0 0 0 0 0\n",
            "I1019 15:03:32.469343 140518079915904 create_pretraining_data.py:161] masked_lm_positions: 2 3 13 14 16 20 26 32 38 39 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_ids: 27 25 153 34 60 511 21 143 46 696 0 0 0 0 0 0 0 0 0 0\n",
            "I1019 15:03:32.469808 140518079915904 create_pretraining_data.py:161] masked_lm_ids: 27 25 153 34 60 511 21 143 46 696 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
            "I1019 15:03:32.470046 140518079915904 create_pretraining_data.py:161] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
            "INFO:tensorflow:next_sentence_labels: 0\n",
            "I1019 15:03:32.470237 140518079915904 create_pretraining_data.py:161] next_sentence_labels: 0\n",
            "INFO:tensorflow:*** Example ***\n",
            "I1019 15:03:32.470839 140518079915904 create_pretraining_data.py:149] *** Example ***\n",
            "INFO:tensorflow:tokens: [CLS] 리 군 [MASK] 공 ##간 ##과 구 ##조 [MASK] 변 ##화 ##를 다루 ##는 ##데 사 ##용 ##된 ##다 [UNK] [SEP] 분 [MASK] [MASK] ##은 물질 [MASK] 조 ##성 ##이 ##나 [MASK] ##합물 ##의 구 ##성 ##요 ##소 등 ##을 결 ##정 ##하는 방 ##법 ##에 대 ##해 ##서 ##징 ##하는 화학 ##의 분 [MASK] ##이 ##다 [UNK] [SEP]\n",
            "I1019 15:03:32.471067 140518079915904 create_pretraining_data.py:151] tokens: [CLS] 리 군 [MASK] 공 ##간 ##과 구 ##조 [MASK] 변 ##화 ##를 다루 ##는 ##데 사 ##용 ##된 ##다 [UNK] [SEP] 분 [MASK] [MASK] ##은 물질 [MASK] 조 ##성 ##이 ##나 [MASK] ##합물 ##의 구 ##성 ##요 ##소 등 ##을 결 ##정 ##하는 방 ##법 ##에 대 ##해 ##서 ##징 ##하는 화학 ##의 분 [MASK] ##이 ##다 [UNK] [SEP]\n",
            "INFO:tensorflow:input_ids: 0 670 310 4 79 158 21 83 213 4 195 51 16 133 6 163 47 88 73 109 2 3 35 4 4 11 134 4 116 37 9 42 4 125 5 83 37 205 75 81 8 84 40 43 86 132 10 32 31 41 604 43 55 5 35 4 9 109 2 3 0 0 0 0\n",
            "I1019 15:03:32.471302 140518079915904 create_pretraining_data.py:161] input_ids: 0 670 310 4 79 158 21 83 213 4 195 51 16 133 6 163 47 88 73 109 2 3 35 4 4 11 134 4 116 37 9 42 4 125 5 83 37 205 75 81 8 84 40 43 86 132 10 32 31 41 604 43 55 5 35 4 9 109 2 3 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0\n",
            "I1019 15:03:32.471509 140518079915904 create_pretraining_data.py:161] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0\n",
            "I1019 15:03:32.471679 140518079915904 create_pretraining_data.py:161] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_positions: 3 9 23 24 25 27 32 50 55 0 0 0 0 0 0 0 0 0 0 0\n",
            "I1019 15:03:32.471817 140518079915904 create_pretraining_data.py:161] masked_lm_positions: 3 9 23 24 25 27 32 50 55 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_ids: 26 696 118 92 11 5 446 140 21 0 0 0 0 0 0 0 0 0 0 0\n",
            "I1019 15:03:32.471958 140518079915904 create_pretraining_data.py:161] masked_lm_ids: 26 696 118 92 11 5 446 140 21 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
            "I1019 15:03:32.472102 140518079915904 create_pretraining_data.py:161] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
            "INFO:tensorflow:next_sentence_labels: 1\n",
            "I1019 15:03:32.472230 140518079915904 create_pretraining_data.py:161] next_sentence_labels: 1\n",
            "INFO:tensorflow:*** Example ***\n",
            "I1019 15:03:32.472584 140518079915904 create_pretraining_data.py:149] *** Example ***\n",
            "INFO:tensorflow:tokens: [CLS] ##과 작 [MASK] ##을 연 [MASK] ##시 ##켜 감 ##상 ##하는 것 ##이 ##고 , 수 ##용 ##론 ##적 관 [MASK] ##의 [MASK] [MASK] ##은 독 [MASK] ##와 [MASK] ##품 ##을 [SEP] ##기 화 ##합물 ##이 ##라 ##서 유 ##기 ##화학 ##에서 ##도 다루 ##어 ##지 ##기 ##도 하 ##나 , [MASK] ##들 화 ##합물 ##에 [MASK] ##련 ##된 물질 ##대 ##사 [SEP]\n",
            "I1019 15:03:32.472752 140518079915904 create_pretraining_data.py:151] tokens: [CLS] ##과 작 [MASK] ##을 연 [MASK] ##시 ##켜 감 ##상 ##하는 것 ##이 ##고 , 수 ##용 ##론 ##적 관 [MASK] ##의 [MASK] [MASK] ##은 독 [MASK] ##와 [MASK] ##품 ##을 [SEP] ##기 화 ##합물 ##이 ##라 ##서 유 ##기 ##화학 ##에서 ##도 다루 ##어 ##지 ##기 ##도 하 ##나 , [MASK] ##들 화 ##합물 ##에 [MASK] ##련 ##된 물질 ##대 ##사 [SEP]\n",
            "INFO:tensorflow:input_ids: 0 21 168 4 8 224 4 54 525 233 53 43 68 9 25 696 29 88 138 36 128 4 5 4 4 11 398 4 57 4 283 8 3 13 135 125 9 46 41 76 13 92 30 26 133 23 17 13 26 101 42 696 4 33 135 125 10 4 374 73 134 49 78 3\n",
            "I1019 15:03:32.472946 140518079915904 create_pretraining_data.py:161] input_ids: 0 21 168 4 8 224 4 54 525 233 53 43 68 9 25 696 29 88 138 36 128 4 5 4 4 11 398 4 57 4 283 8 3 13 135 125 9 46 41 76 13 92 30 26 133 23 17 13 26 101 42 696 4 33 135 125 10 4 374 73 134 49 78 3\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I1019 15:03:32.473107 140518079915904 create_pretraining_data.py:161] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I1019 15:03:32.473260 140518079915904 create_pretraining_data.py:161] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:masked_lm_positions: 3 6 10 21 23 24 27 29 52 57 0 0 0 0 0 0 0 0 0 0\n",
            "I1019 15:03:32.473398 140518079915904 create_pretraining_data.py:161] masked_lm_positions: 3 6 10 21 23 24 27 29 52 57 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_ids: 283 204 53 332 233 53 28 168 12 128 0 0 0 0 0 0 0 0 0 0\n",
            "I1019 15:03:32.473551 140518079915904 create_pretraining_data.py:161] masked_lm_ids: 283 204 53 332 233 53 28 168 12 128 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
            "I1019 15:03:32.473690 140518079915904 create_pretraining_data.py:161] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
            "INFO:tensorflow:next_sentence_labels: 1\n",
            "I1019 15:03:32.473814 140518079915904 create_pretraining_data.py:161] next_sentence_labels: 1\n",
            "INFO:tensorflow:*** Example ***\n",
            "I1019 15:03:32.474229 140518079915904 create_pretraining_data.py:149] *** Example ***\n",
            "INFO:tensorflow:tokens: [CLS] 세 ##르 ##비 [MASK] ##계 정 ##권 같 [MASK] 미 ##국 정 ##부 ##에 대 ##해 협 ##상 ##을 거 ##부 ##하 ##면 ##서 사 ##태 ##의 위 ##기 ##를 초 [SEP] ##성 ##하 ##고 있 [MASK] 국 ##가 [MASK] 선 ##정 ##하는 [MASK] ##준 ##에 [MASK] 정 ##보 ##는 [MASK] 포 ##함 [MASK] ##준 \" [MASK] ##락 ##을 [MASK] ##해 설 [SEP]\n",
            "I1019 15:03:32.474476 140518079915904 create_pretraining_data.py:151] tokens: [CLS] 세 ##르 ##비 [MASK] ##계 정 ##권 같 [MASK] 미 ##국 정 ##부 ##에 대 ##해 협 ##상 ##을 거 ##부 ##하 ##면 ##서 사 ##태 ##의 위 ##기 ##를 초 [SEP] ##성 ##하 ##고 있 [MASK] 국 ##가 [MASK] 선 ##정 ##하는 [MASK] ##준 ##에 [MASK] 정 ##보 ##는 [MASK] 포 ##함 [MASK] ##준 \" [MASK] ##락 ##을 [MASK] ##해 설 [SEP]\n",
            "INFO:tensorflow:input_ids: 0 173 148 178 4 94 74 219 208 4 90 48 74 64 10 32 31 271 53 8 478 64 18 131 41 47 326 5 111 13 16 255 3 37 18 25 60 4 127 20 4 223 40 43 4 268 10 4 74 263 6 4 165 136 4 268 171 4 794 8 4 31 312 3\n",
            "I1019 15:03:32.474708 140518079915904 create_pretraining_data.py:161] input_ids: 0 173 148 178 4 94 74 219 208 4 90 48 74 64 10 32 31 271 53 8 478 64 18 131 41 47 326 5 111 13 16 255 3 37 18 25 60 4 127 20 4 223 40 43 4 268 10 4 74 263 6 4 165 136 4 268 171 4 794 8 4 31 312 3\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I1019 15:03:32.474889 140518079915904 create_pretraining_data.py:161] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I1019 15:03:32.475059 140518079915904 create_pretraining_data.py:161] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:masked_lm_positions: 4 9 37 40 44 47 51 54 57 60 0 0 0 0 0 0 0 0 0 0\n",
            "I1019 15:03:32.475194 140518079915904 create_pretraining_data.py:161] masked_lm_positions: 4 9 37 40 44 47 51 54 57 60 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_ids: 97 9 6 16 52 110 171 52 307 316 0 0 0 0 0 0 0 0 0 0\n",
            "I1019 15:03:32.475333 140518079915904 create_pretraining_data.py:161] masked_lm_ids: 97 9 6 16 52 110 171 52 307 316 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
            "I1019 15:03:32.475513 140518079915904 create_pretraining_data.py:161] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
            "INFO:tensorflow:next_sentence_labels: 1\n",
            "I1019 15:03:32.475656 140518079915904 create_pretraining_data.py:161] next_sentence_labels: 1\n",
            "INFO:tensorflow:*** Example ***\n",
            "I1019 15:03:32.476011 140518079915904 create_pretraining_data.py:149] *** Example ***\n",
            "INFO:tensorflow:tokens: [CLS] , 면 ##역 ##학 , 바 ##이 ##러 ##스 ##학 ##의 ##이다. ##전 ##에 [MASK] 영 ##향 [MASK] 끼 ##쳤 ##다 [UNK] 유 ##기 ##화학 ##은 [MASK] ##소 ##로 이 ##루 [SEP] ##을 [MASK] ##소 [MASK] ##으 ##며 실 ##험 ##은 지 ##구 [MASK] 화 [MASK] , [MASK] ##기 및 물 ##과 같 ##은 고 ##전 ##적인 4 가 ##지 [MASK] ##만 [SEP]\n",
            "I1019 15:03:32.476208 140518079915904 create_pretraining_data.py:151] tokens: [CLS] , 면 ##역 ##학 , 바 ##이 ##러 ##스 ##학 ##의 ##이다. ##전 ##에 [MASK] 영 ##향 [MASK] 끼 ##쳤 ##다 [UNK] 유 ##기 ##화학 ##은 [MASK] ##소 ##로 이 ##루 [SEP] ##을 [MASK] ##소 [MASK] ##으 ##며 실 ##험 ##은 지 ##구 [MASK] 화 [MASK] , [MASK] ##기 및 물 ##과 같 ##은 고 ##전 ##적인 4 가 ##지 [MASK] ##만 [SEP]\n",
            "INFO:tensorflow:input_ids: 0 696 953 265 22 696 954 9 121 45 22 5 50 65 10 4 272 375 4 955 419 109 2 76 13 92 11 4 75 19 12 298 3 8 4 75 4 114 77 166 305 11 142 103 4 135 4 696 4 13 193 124 21 208 11 144 65 96 400 82 17 4 147 3\n",
            "I1019 15:03:32.476396 140518079915904 create_pretraining_data.py:161] input_ids: 0 696 953 265 22 696 954 9 121 45 22 5 50 65 10 4 272 375 4 955 419 109 2 76 13 92 11 4 75 19 12 298 3 8 4 75 4 114 77 166 305 11 142 103 4 135 4 696 4 13 193 124 21 208 11 144 65 96 400 82 17 4 147 3\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I1019 15:03:32.476580 140518079915904 create_pretraining_data.py:161] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I1019 15:03:32.476752 140518079915904 create_pretraining_data.py:161] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:masked_lm_positions: 12 15 18 27 34 36 44 46 48 61 0 0 0 0 0 0 0 0 0 0\n",
            "I1019 15:03:32.476891 140518079915904 create_pretraining_data.py:161] masked_lm_positions: 12 15 18 27 34 36 44 46 48 61 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_ids: 61 367 8 410 687 98 696 465 79 123 0 0 0 0 0 0 0 0 0 0\n",
            "I1019 15:03:32.477044 140518079915904 create_pretraining_data.py:161] masked_lm_ids: 61 367 8 410 687 98 696 465 79 123 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
            "I1019 15:03:32.477183 140518079915904 create_pretraining_data.py:161] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
            "INFO:tensorflow:next_sentence_labels: 1\n",
            "I1019 15:03:32.477306 140518079915904 create_pretraining_data.py:161] next_sentence_labels: 1\n",
            "INFO:tensorflow:*** Example ***\n",
            "I1019 15:03:32.477673 140518079915904 create_pretraining_data.py:149] *** Example ***\n",
            "INFO:tensorflow:tokens: [CLS] ##부 ##터 수 ##주 ##일 후 김 ##일 ##성 ##이 [MASK] ##자 ##기 사 ##망 ##하여 김 ##일 ##성 ##과 김 [MASK] ##삼 ##의 정 ##상 [MASK] ##담 ##은 이 ##루 [SEP] 은 전 ##기 ##와 자 ##기 [MASK] 발 ##생 , 전 ##기 ##장 ##과 자 ##기 ##장 , [MASK] ##하 [MASK] ##도 ##와 훨 ##류 밀 ##도 ##의 형 [MASK] [SEP]\n",
            "I1019 15:03:32.477840 140518079915904 create_pretraining_data.py:151] tokens: [CLS] ##부 ##터 수 ##주 ##일 후 김 ##일 ##성 ##이 [MASK] ##자 ##기 사 ##망 ##하여 김 ##일 ##성 ##과 김 [MASK] ##삼 ##의 정 ##상 [MASK] ##담 ##은 이 ##루 [SEP] 은 전 ##기 ##와 자 ##기 [MASK] 발 ##생 , 전 ##기 ##장 ##과 자 ##기 ##장 , [MASK] ##하 [MASK] ##도 ##와 훨 ##류 밀 ##도 ##의 형 [MASK] [SEP]\n",
            "INFO:tensorflow:input_ids: 0 64 107 29 130 108 222 366 108 37 9 4 28 13 47 588 129 366 108 37 21 366 4 504 5 74 53 4 724 11 12 298 3 653 72 13 57 106 13 4 61 612 696 72 13 157 21 106 13 157 696 4 18 4 26 57 872 248 562 26 5 239 4 3\n",
            "I1019 15:03:32.478062 140518079915904 create_pretraining_data.py:161] input_ids: 0 64 107 29 130 108 222 366 108 37 9 4 28 13 47 588 129 366 108 37 21 366 4 504 5 74 53 4 724 11 12 298 3 653 72 13 57 106 13 4 61 612 696 72 13 157 21 106 13 157 696 4 18 4 26 57 872 248 562 26 5 239 4 3\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I1019 15:03:32.478225 140518079915904 create_pretraining_data.py:161] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I1019 15:03:32.478420 140518079915904 create_pretraining_data.py:161] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:masked_lm_positions: 6 11 22 27 34 39 51 53 56 62 0 0 0 0 0 0 0 0 0 0\n",
            "I1019 15:03:32.478575 140518079915904 create_pretraining_data.py:161] masked_lm_positions: 6 11 22 27 34 39 51 53 56 62 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_ids: 222 870 457 322 72 5 72 562 72 37 0 0 0 0 0 0 0 0 0 0\n",
            "I1019 15:03:32.478746 140518079915904 create_pretraining_data.py:161] masked_lm_ids: 222 870 457 322 72 5 72 562 72 37 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
            "I1019 15:03:32.478904 140518079915904 create_pretraining_data.py:161] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
            "INFO:tensorflow:next_sentence_labels: 1\n",
            "I1019 15:03:32.479049 140518079915904 create_pretraining_data.py:161] next_sentence_labels: 1\n",
            "INFO:tensorflow:*** Example ***\n",
            "I1019 15:03:32.479434 140518079915904 create_pretraining_data.py:149] *** Example ***\n",
            "INFO:tensorflow:tokens: [CLS] ##거 ##나 , 이 ##야 ##기 ##가 혼 ##란 ##스 ##러 ##워 신 ##뢰 ##성 ##을 주 ##지 않 ##거 ##나 , 인 ##물 [MASK] ##의 [MASK] [MASK] [MASK] 일 [MASK] [SEP] ##은 가 ##우 ##스 법 ##칙 , 가 ##우 ##스 자 [MASK] 법 ##칙 , [MASK] [MASK] ##데 ##이 전 ##자 ##기 유 ##도 법 ##칙 , 앙 ##페 ##르 [SEP]\n",
            "I1019 15:03:32.479612 140518079915904 create_pretraining_data.py:151] tokens: [CLS] ##거 ##나 , 이 ##야 ##기 ##가 혼 ##란 ##스 ##러 ##워 신 ##뢰 ##성 ##을 주 ##지 않 ##거 ##나 , 인 ##물 [MASK] ##의 [MASK] [MASK] [MASK] 일 [MASK] [SEP] ##은 가 ##우 ##스 법 ##칙 , 가 ##우 ##스 자 [MASK] 법 ##칙 , [MASK] [MASK] ##데 ##이 전 ##자 ##기 유 ##도 법 ##칙 , 앙 ##페 ##르 [SEP]\n",
            "INFO:tensorflow:input_ids: 0 201 42 696 12 93 13 20 446 214 45 121 452 395 770 37 8 71 17 210 201 42 696 56 216 4 5 4 4 4 80 4 3 11 82 159 45 342 302 696 82 159 45 106 4 342 302 696 4 4 163 9 72 28 13 76 26 342 302 696 965 621 148 3\n",
            "I1019 15:03:32.479790 140518079915904 create_pretraining_data.py:161] input_ids: 0 201 42 696 12 93 13 20 446 214 45 121 452 395 770 37 8 71 17 210 201 42 696 56 216 4 5 4 4 4 80 4 3 11 82 159 45 342 302 696 82 159 45 106 4 342 302 696 4 4 163 9 72 28 13 76 26 342 302 696 965 621 148 3\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I1019 15:03:32.479980 140518079915904 create_pretraining_data.py:161] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I1019 15:03:32.480141 140518079915904 create_pretraining_data.py:161] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:masked_lm_positions: 25 27 28 29 31 39 41 44 48 49 0 0 0 0 0 0 0 0 0 0\n",
            "I1019 15:03:32.573221 140518079915904 create_pretraining_data.py:161] masked_lm_positions: 25 27 28 29 31 39 41 44 48 49 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_ids: 33 256 350 10 218 696 159 13 964 121 0 0 0 0 0 0 0 0 0 0\n",
            "I1019 15:03:32.573419 140518079915904 create_pretraining_data.py:161] masked_lm_ids: 33 256 350 10 218 696 159 13 964 121 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
            "I1019 15:03:32.573632 140518079915904 create_pretraining_data.py:161] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
            "INFO:tensorflow:next_sentence_labels: 1\n",
            "I1019 15:03:32.573809 140518079915904 create_pretraining_data.py:161] next_sentence_labels: 1\n",
            "INFO:tensorflow:*** Example ***\n",
            "I1019 15:03:32.574364 140518079915904 create_pretraining_data.py:149] *** Example ***\n",
            "INFO:tensorflow:tokens: [CLS] ##절 기 ##기 등 물 ##리 ##화학 ##에서 사 ##용 [MASK] [MASK] [MASK] 장 ##비 ##나 실 ##험 방 ##법 ##들 ##은 다 ##른 화학 [MASK] 분 ##과 ##에서 ##도 [MASK] [SEP] ##성 ##자 [MASK] [MASK] [MASK] ##자 ##로 구 ##성 ##되 ##어 있 ##는 원자 ##핵 ##을 가 ##지 ##고 있 ##으 ##며 전 ##자 ##는 이 [MASK] ##변 ##에 오 [SEP]\n",
            "I1019 15:03:32.574612 140518079915904 create_pretraining_data.py:151] tokens: [CLS] ##절 기 ##기 등 물 ##리 ##화학 ##에서 사 ##용 [MASK] [MASK] [MASK] 장 ##비 ##나 실 ##험 방 ##법 ##들 ##은 다 ##른 화학 [MASK] 분 ##과 ##에서 ##도 [MASK] [SEP] ##성 ##자 [MASK] [MASK] [MASK] ##자 ##로 구 ##성 ##되 ##어 있 ##는 원자 ##핵 ##을 가 ##지 ##고 있 ##으 ##며 전 ##자 ##는 이 [MASK] ##변 ##에 오 [SEP]\n",
            "INFO:tensorflow:input_ids: 0 420 52 13 81 124 27 92 30 47 88 4 4 4 477 178 42 166 305 86 132 33 11 105 169 55 4 35 21 30 26 4 3 37 28 4 4 4 28 19 83 37 34 23 60 6 115 378 8 82 17 25 60 114 77 72 28 6 12 4 456 10 274 3\n",
            "I1019 15:03:32.574829 140518079915904 create_pretraining_data.py:161] input_ids: 0 420 52 13 81 124 27 92 30 47 88 4 4 4 477 178 42 166 305 86 132 33 11 105 169 55 4 35 21 30 26 4 3 37 28 4 4 4 28 19 83 37 34 23 60 6 115 378 8 82 17 25 60 114 77 72 28 6 12 4 456 10 274 3\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I1019 15:03:32.575045 140518079915904 create_pretraining_data.py:161] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I1019 15:03:32.575248 140518079915904 create_pretraining_data.py:161] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:masked_lm_positions: 11 12 13 22 26 31 35 36 37 59 0 0 0 0 0 0 0 0 0 0\n",
            "I1019 15:03:32.575439 140518079915904 create_pretraining_data.py:161] masked_lm_positions: 11 12 13 22 26 31 35 36 37 59 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_ids: 43 166 305 11 5 290 57 66 37 71 0 0 0 0 0 0 0 0 0 0\n",
            "I1019 15:03:32.575632 140518079915904 create_pretraining_data.py:161] masked_lm_ids: 43 166 305 11 5 290 57 66 37 71 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
            "I1019 15:03:32.575789 140518079915904 create_pretraining_data.py:161] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
            "INFO:tensorflow:next_sentence_labels: 1\n",
            "I1019 15:03:32.575927 140518079915904 create_pretraining_data.py:161] next_sentence_labels: 1\n",
            "INFO:tensorflow:*** Example ***\n",
            "I1019 15:03:32.576485 140518079915904 create_pretraining_data.py:149] *** Example ***\n",
            "INFO:tensorflow:tokens: [CLS] 이 외 ##에 ##도 화학 ##의 분 ##과 [MASK] 매 [MASK] 다 ##양 ##하 ##다 [UNK] [SEP] [MASK] [MASK] ##어 ##져 나 ##와 자 ##유 ##전 ##자 ##를 생 [MASK] ##려 ##게 되 [MASK] 생 ##성 [MASK] ##는 결 ##합 ##을 의 ##미 ##한 ##다 [UNK] 금 [MASK] ##의 특 ##성 ##인 연 ##성 ##과 전 ##성 ##이 생 ##성 ##되 ##는 [SEP]\n",
            "I1019 15:03:32.576691 140518079915904 create_pretraining_data.py:151] tokens: [CLS] 이 외 ##에 ##도 화학 ##의 분 ##과 [MASK] 매 [MASK] 다 ##양 ##하 ##다 [UNK] [SEP] [MASK] [MASK] ##어 ##져 나 ##와 자 ##유 ##전 ##자 ##를 생 [MASK] ##려 ##게 되 [MASK] 생 ##성 [MASK] ##는 결 ##합 ##을 의 ##미 ##한 ##다 [UNK] 금 [MASK] ##의 특 ##성 ##인 연 ##성 ##과 전 ##성 ##이 생 ##성 ##되 ##는 [SEP]\n",
            "INFO:tensorflow:input_ids: 0 12 405 10 26 55 5 35 21 4 290 4 105 422 18 109 2 3 4 4 23 468 91 57 106 215 65 28 16 154 4 294 87 232 4 154 37 4 6 84 59 8 143 145 14 109 2 196 4 5 194 37 63 224 37 21 72 37 9 154 37 34 6 3\n",
            "I1019 15:03:32.576896 140518079915904 create_pretraining_data.py:161] input_ids: 0 12 405 10 26 55 5 35 21 4 290 4 105 422 18 109 2 3 4 4 23 468 91 57 106 215 65 28 16 154 4 294 87 232 4 154 37 4 6 84 59 8 143 145 14 109 2 196 4 5 194 37 63 224 37 21 72 37 9 154 37 34 6 3\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I1019 15:03:32.577089 140518079915904 create_pretraining_data.py:161] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I1019 15:03:32.577260 140518079915904 create_pretraining_data.py:161] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:masked_lm_positions: 9 11 18 19 26 30 31 34 37 48 0 0 0 0 0 0 0 0 0 0\n",
            "I1019 15:03:32.577419 140518079915904 create_pretraining_data.py:161] masked_lm_positions: 9 11 18 19 26 30 31 34 37 48 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_ids: 6 159 9 550 65 37 18 23 34 153 0 0 0 0 0 0 0 0 0 0\n",
            "I1019 15:03:32.577595 140518079915904 create_pretraining_data.py:161] masked_lm_ids: 6 159 9 550 65 37 18 23 34 153 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
            "I1019 15:03:32.577750 140518079915904 create_pretraining_data.py:161] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
            "INFO:tensorflow:next_sentence_labels: 1\n",
            "I1019 15:03:32.577893 140518079915904 create_pretraining_data.py:161] next_sentence_labels: 1\n",
            "INFO:tensorflow:*** Example ***\n",
            "I1019 15:03:32.578379 140518079915904 create_pretraining_data.py:149] *** Example ***\n",
            "INFO:tensorflow:tokens: [CLS] 위 기 ##준 ##에 논 ##거 ##하여 이 목 ##록 ##은 다 [MASK] [MASK] ##0 ##6 ##개 국 ##가 [MASK] [MASK] ##함 [MASK] ##고 있 ##다 [MASK] [SEP] [MASK] 광 ##물 ##의 구 ##성 ##이 ##나 새 원소 ##의 발 ##견 ##이 [MASK] ##요 관 ##심 ##사 ##였 ##고 여 ##기 ##서 ##부 ##터 지 ##구 ##화학 ##이 분 [MASK] ##되 ##었 [SEP]\n",
            "I1019 15:03:32.578586 140518079915904 create_pretraining_data.py:151] tokens: [CLS] 위 기 ##준 ##에 논 ##거 ##하여 이 목 ##록 ##은 다 [MASK] [MASK] ##0 ##6 ##개 국 ##가 [MASK] [MASK] ##함 [MASK] ##고 있 ##다 [MASK] [SEP] [MASK] 광 ##물 ##의 구 ##성 ##이 ##나 새 원소 ##의 발 ##견 ##이 [MASK] ##요 관 ##심 ##사 ##였 ##고 여 ##기 ##서 ##부 ##터 지 ##구 ##화학 ##이 분 [MASK] ##되 ##었 [SEP]\n",
            "INFO:tensorflow:input_ids: 0 111 52 268 10 234 201 129 12 226 187 11 105 4 4 58 177 303 127 20 4 4 136 4 25 60 109 4 3 4 552 216 5 83 37 9 42 402 123 5 61 179 9 4 205 128 230 78 161 25 258 13 41 64 107 142 103 92 9 35 4 34 221 3\n",
            "I1019 15:03:32.578799 140518079915904 create_pretraining_data.py:161] input_ids: 0 111 52 268 10 234 201 129 12 226 187 11 105 4 4 58 177 303 127 20 4 4 136 4 25 60 109 4 3 4 552 216 5 83 37 9 42 402 123 5 61 179 9 4 205 128 230 78 161 25 258 13 41 64 107 142 103 92 9 35 4 34 221 3\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I1019 15:03:32.578978 140518079915904 create_pretraining_data.py:161] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I1019 15:03:32.579144 140518079915904 create_pretraining_data.py:161] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:masked_lm_positions: 13 14 20 21 23 27 29 39 43 60 0 0 0 0 0 0 0 0 0 0\n",
            "I1019 15:03:32.579290 140518079915904 create_pretraining_data.py:161] masked_lm_positions: 13 14 20 21 23 27 29 39 43 60 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_ids: 202 235 16 165 18 2 6 5 71 13 0 0 0 0 0 0 0 0 0 0\n",
            "I1019 15:03:32.579459 140518079915904 create_pretraining_data.py:161] masked_lm_ids: 202 235 16 165 18 2 6 5 71 13 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
            "I1019 15:03:32.579612 140518079915904 create_pretraining_data.py:161] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
            "INFO:tensorflow:next_sentence_labels: 1\n",
            "I1019 15:03:32.579740 140518079915904 create_pretraining_data.py:161] next_sentence_labels: 1\n",
            "INFO:tensorflow:*** Example ***\n",
            "I1019 15:03:32.580184 140518079915904 create_pretraining_data.py:149] *** Example ***\n",
            "INFO:tensorflow:tokens: [CLS] 의 [MASK] ##성 [MASK] ##인 ##데 , 질 ##량 ##은 서 ##로 달 ##라 [MASK] 원소 ##의 주 ##기 ##율 ##표 ##에서 [MASK] ##은 장 ##소 [MASK] [MASK] ##열 [MASK] [MASK] 데 ##서 [SEP] 19 ##9 ##0 ##년 ##대 체 ##첸 공 ##화 ##국 ##에 남 ##아 있 ##던 러 ##시 ##아 ##인 ##은 약 6 ##만 명 ##이 [MASK] ##다 [UNK] [SEP]\n",
            "I1019 15:03:32.580373 140518079915904 create_pretraining_data.py:151] tokens: [CLS] 의 [MASK] ##성 [MASK] ##인 ##데 , 질 ##량 ##은 서 ##로 달 ##라 [MASK] 원소 ##의 주 ##기 ##율 ##표 ##에서 [MASK] ##은 장 ##소 [MASK] [MASK] ##열 [MASK] [MASK] 데 ##서 [SEP] 19 ##9 ##0 ##년 ##대 체 ##첸 공 ##화 ##국 ##에 남 ##아 있 ##던 러 ##시 ##아 ##인 ##은 약 6 ##만 명 ##이 [MASK] ##다 [UNK] [SEP]\n",
            "INFO:tensorflow:input_ids: 0 143 4 37 4 63 163 696 369 250 11 260 19 440 46 4 123 5 71 13 430 464 30 4 11 477 75 4 4 306 4 4 335 41 3 100 197 58 62 49 150 170 79 51 48 10 541 97 60 453 276 54 97 63 11 370 473 147 404 9 4 109 2 3\n",
            "I1019 15:03:32.580577 140518079915904 create_pretraining_data.py:161] input_ids: 0 143 4 37 4 63 163 696 369 250 11 260 19 440 46 4 123 5 71 13 430 464 30 4 11 477 75 4 4 306 4 4 335 41 3 100 197 58 62 49 150 170 79 51 48 10 541 97 60 453 276 54 97 63 11 370 473 147 404 9 4 109 2 3\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I1019 15:03:32.580773 140518079915904 create_pretraining_data.py:161] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I1019 15:03:32.580971 140518079915904 create_pretraining_data.py:161] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:masked_lm_positions: 2 4 15 16 23 27 28 30 31 60 0 0 0 0 0 0 0 0 0 0\n",
            "I1019 15:03:32.581161 140518079915904 create_pretraining_data.py:161] masked_lm_positions: 2 4 15 16 23 27 28 30 31 60 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_ids: 408 23 26 123 208 10 556 34 6 221 0 0 0 0 0 0 0 0 0 0\n",
            "I1019 15:03:32.581338 140518079915904 create_pretraining_data.py:161] masked_lm_ids: 408 23 26 123 208 10 556 34 6 221 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
            "I1019 15:03:32.581551 140518079915904 create_pretraining_data.py:161] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
            "INFO:tensorflow:next_sentence_labels: 1\n",
            "I1019 15:03:32.581705 140518079915904 create_pretraining_data.py:161] next_sentence_labels: 1\n",
            "INFO:tensorflow:*** Example ***\n",
            "I1019 15:03:32.582267 140518079915904 create_pretraining_data.py:149] *** Example ***\n",
            "INFO:tensorflow:tokens: [CLS] 시 ##는 [MASK] [MASK] ##시 [UNK] 자 ##유 ##시 [UNK] 산 ##문 ##시 ##로 , 또 ##한 서 땅 ##시 [MASK] 서 ##정 ##시 ##로 [MASK] [MASK] ##다 [UNK] [SEP] [MASK] ##간 ##에 대한 이 ##해 ##는 [MASK] ##두 해 ##석 기 ##하 ##학 , 미 ##분 ##기 ##하 ##학 , 대 ##수 ##기 ##하 ##학 ##에 중 ##요 ##한 역 ##할 [SEP]\n",
            "I1019 15:03:32.582493 140518079915904 create_pretraining_data.py:151] tokens: [CLS] 시 ##는 [MASK] [MASK] ##시 [UNK] 자 ##유 ##시 [UNK] 산 ##문 ##시 ##로 , 또 ##한 서 땅 ##시 [MASK] 서 ##정 ##시 ##로 [MASK] [MASK] ##다 [UNK] [SEP] [MASK] ##간 ##에 대한 이 ##해 ##는 [MASK] ##두 해 ##석 기 ##하 ##학 , 미 ##분 ##기 ##하 ##학 , 대 ##수 ##기 ##하 ##학 ##에 중 ##요 ##한 역 ##할 [SEP]\n",
            "INFO:tensorflow:input_ids: 0 167 6 4 4 54 2 106 215 54 2 341 69 54 19 696 104 14 260 846 54 4 260 40 54 19 4 4 109 2 3 4 158 10 110 12 31 6 4 429 188 118 52 18 22 696 90 89 13 18 22 696 32 39 13 18 22 10 66 205 14 252 207 3\n",
            "I1019 15:03:32.582695 140518079915904 create_pretraining_data.py:161] input_ids: 0 167 6 4 4 54 2 106 215 54 2 341 69 54 19 696 104 14 260 846 54 4 260 40 54 19 4 4 109 2 3 4 158 10 110 12 31 6 4 429 188 118 52 18 22 696 90 89 13 18 22 696 32 39 13 18 22 10 66 205 14 252 207 3\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I1019 15:03:32.582883 140518079915904 create_pretraining_data.py:161] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I1019 15:03:32.583095 140518079915904 create_pretraining_data.py:161] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:masked_lm_positions: 3 4 10 19 20 21 26 27 31 38 0 0 0 0 0 0 0 0 0 0\n",
            "I1019 15:03:32.583264 140518079915904 create_pretraining_data.py:161] masked_lm_positions: 3 4 10 19 20 21 26 27 31 38 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_ids: 74 353 2 78 54 57 91 776 79 259 0 0 0 0 0 0 0 0 0 0\n",
            "I1019 15:03:32.583499 140518079915904 create_pretraining_data.py:161] masked_lm_ids: 74 353 2 78 54 57 91 776 79 259 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
            "I1019 15:03:32.584398 140518079915904 create_pretraining_data.py:161] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
            "INFO:tensorflow:next_sentence_labels: 1\n",
            "I1019 15:03:32.584645 140518079915904 create_pretraining_data.py:161] next_sentence_labels: 1\n",
            "INFO:tensorflow:*** Example ***\n",
            "I1019 15:03:32.585322 140518079915904 create_pretraining_data.py:149] *** Example ***\n",
            "INFO:tensorflow:tokens: [CLS] ##아 ##주 상 ##원 [MASK] ##원 ##을 두 ##번 연 ##임 ##했 ##으 ##며 , 19 ##7 [MASK] ##년 ##부 ##터 19 ##7 ##5 ##년 ##까 ##지 [MASK] ##지 ##아 지 ##사 ##로 [SEP] 조 ##지 ##아 주 ##지 ##사 [MASK] [MASK] [MASK] [MASK] ##서 [MASK] [MASK] ##국 ##에 사 ##는 흑 ##인 등 ##용 ##법 ##을 내 ##세 ##웠 ##다 [UNK] [SEP]\n",
            "I1019 15:03:32.585566 140518079915904 create_pretraining_data.py:151] tokens: [CLS] ##아 ##주 상 ##원 [MASK] ##원 ##을 두 ##번 연 ##임 ##했 ##으 ##며 , 19 ##7 [MASK] ##년 ##부 ##터 19 ##7 ##5 ##년 ##까 ##지 [MASK] ##지 ##아 지 ##사 ##로 [SEP] 조 ##지 ##아 주 ##지 ##사 [MASK] [MASK] [MASK] [MASK] ##서 [MASK] [MASK] ##국 ##에 사 ##는 흑 ##인 등 ##용 ##법 ##을 내 ##세 ##웠 ##다 [UNK] [SEP]\n",
            "INFO:tensorflow:input_ids: 0 97 130 149 227 4 227 8 435 567 224 241 98 114 77 696 100 175 4 62 64 107 100 175 319 62 280 17 4 17 97 142 78 19 3 116 17 97 71 17 78 4 4 4 4 41 4 4 48 10 47 6 849 63 81 88 132 8 190 211 495 109 2 3\n",
            "I1019 15:03:32.585753 140518079915904 create_pretraining_data.py:161] input_ids: 0 97 130 149 227 4 227 8 435 567 224 241 98 114 77 696 100 175 4 62 64 107 100 175 319 62 280 17 4 17 97 142 78 19 3 116 17 97 71 17 78 4 4 4 4 41 4 4 48 10 47 6 849 63 81 88 132 8 190 211 495 109 2 3\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I1019 15:03:32.672906 140518079915904 create_pretraining_data.py:161] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I1019 15:03:32.673155 140518079915904 create_pretraining_data.py:161] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:masked_lm_positions: 5 18 22 28 41 42 43 44 46 47 0 0 0 0 0 0 0 0 0 0\n",
            "I1019 15:03:32.673318 140518079915904 create_pretraining_data.py:161] masked_lm_positions: 5 18 22 28 41 42 43 44 46 47 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_ids: 5 261 100 116 19 142 494 131 696 90 0 0 0 0 0 0 0 0 0 0\n",
            "I1019 15:03:32.673533 140518079915904 create_pretraining_data.py:161] masked_lm_ids: 5 261 100 116 19 142 494 131 696 90 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
            "I1019 15:03:32.673737 140518079915904 create_pretraining_data.py:161] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
            "INFO:tensorflow:next_sentence_labels: 0\n",
            "I1019 15:03:32.673907 140518079915904 create_pretraining_data.py:161] next_sentence_labels: 0\n",
            "INFO:tensorflow:*** Example ***\n",
            "I1019 15:03:32.674536 140518079915904 create_pretraining_data.py:149] *** Example ***\n",
            "INFO:tensorflow:tokens: [CLS] ##상 ##인 양 , 구 ##조 , 공 ##간 [MASK] 변 ##화 [MASK] 대 ##응 ##되 ##며 [MASK] ##료 ##들 ##을 다루 [MASK] 수학 ##의 [MASK] ##야 ##를 각 ##각 산 [SEP] ##몇 인 ##기 ##있 ##는 기 ##록 ##형 ##태 ##의 작 ##업 ##들 , [MASK] ##위 \" 대 ##중 ##문 ##학 [MASK] 사 ##이 [MASK] ##는 인 ##식 ##가 ##능 [SEP]\n",
            "I1019 15:03:32.674746 140518079915904 create_pretraining_data.py:151] tokens: [CLS] ##상 ##인 양 , 구 ##조 , 공 ##간 [MASK] 변 ##화 [MASK] 대 ##응 ##되 ##며 [MASK] ##료 ##들 ##을 다루 [MASK] 수학 ##의 [MASK] ##야 ##를 각 ##각 산 [SEP] ##몇 인 ##기 ##있 ##는 기 ##록 ##형 ##태 ##의 작 ##업 ##들 , [MASK] ##위 \" 대 ##중 ##문 ##학 [MASK] 사 ##이 [MASK] ##는 인 ##식 ##가 ##능 [SEP]\n",
            "INFO:tensorflow:input_ids: 0 53 63 160 696 83 213 696 79 158 4 195 51 4 32 139 34 77 4 425 33 8 133 4 70 5 4 93 16 371 282 341 3 610 56 13 427 6 52 187 353 326 5 168 345 33 696 4 120 171 32 304 69 22 4 47 9 4 6 56 122 20 330 3\n",
            "I1019 15:03:32.674948 140518079915904 create_pretraining_data.py:161] input_ids: 0 53 63 160 696 83 213 696 79 158 4 195 51 4 32 139 34 77 4 425 33 8 133 4 70 5 4 93 16 371 282 341 3 610 56 13 427 6 52 187 353 326 5 168 345 33 696 4 120 171 32 304 69 22 4 47 9 4 6 56 122 20 330 3\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I1019 15:03:32.675135 140518079915904 create_pretraining_data.py:161] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I1019 15:03:32.675299 140518079915904 create_pretraining_data.py:161] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:masked_lm_positions: 10 13 18 19 23 26 47 52 54 57 0 0 0 0 0 0 0 0 0 0\n",
            "I1019 15:03:32.675478 140518079915904 create_pretraining_data.py:161] masked_lm_positions: 10 13 18 19 23 26 47 52 54 57 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_ids: 193 10 696 12 6 35 254 69 171 10 0 0 0 0 0 0 0 0 0 0\n",
            "I1019 15:03:32.675620 140518079915904 create_pretraining_data.py:161] masked_lm_ids: 193 10 696 12 6 35 254 69 171 10 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
            "I1019 15:03:32.675766 140518079915904 create_pretraining_data.py:161] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
            "INFO:tensorflow:next_sentence_labels: 1\n",
            "I1019 15:03:32.675896 140518079915904 create_pretraining_data.py:161] next_sentence_labels: 1\n",
            "INFO:tensorflow:Wrote 2139 total instances\n",
            "I1019 15:03:33.081116 140518079915904 create_pretraining_data.py:166] Wrote 2139 total instances\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AmF713AzWl1B"
      },
      "source": [
        "# BERT 학습"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NBl1RNviWrEJ"
      },
      "source": [
        "이제 만들어진 학습 데이터를 이용해서 실제로 BERT를 학습해보도록 하겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GcqCexeMW7fz",
        "outputId": "1f114429-86b2-40c8-e3dc-52bf6147f8c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!python /content/bert/run_pretraining.py \\\n",
        "--input_file=/content/wiki_20190620_small_64_tf.record \\\n",
        "--output_dir=/content/my_pretrained_model \\\n",
        "--do_train=True \\\n",
        "--do_eval=True \\\n",
        "--bert_config_file=/content/WordPieceTokenizer/bert_config.json \\\n",
        "--train_batch_size=4 \\\n",
        "--max_seq_length=64 \\\n",
        "--max_predictions_per_seq=20 \\\n",
        "--num_train_steps=10 \\\n",
        "--learning_rate=1e-4 \\\n",
        "--save_checkpoints_steps=5 \\\n",
        "--do_lower_case=False"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /content/bert/optimization.py:87: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/bert/run_pretraining.py:493: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/bert/run_pretraining.py:407: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.\n",
            "\n",
            "W1019 15:06:27.593816 140597344753536 module_wrapper.py:139] From /content/bert/run_pretraining.py:407: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/bert/run_pretraining.py:407: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.\n",
            "\n",
            "W1019 15:06:27.594081 140597344753536 module_wrapper.py:139] From /content/bert/run_pretraining.py:407: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/bert/modeling.py:93: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "W1019 15:06:27.594388 140597344753536 module_wrapper.py:139] From /content/bert/modeling.py:93: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/bert/run_pretraining.py:414: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.\n",
            "\n",
            "W1019 15:06:27.595283 140597344753536 module_wrapper.py:139] From /content/bert/run_pretraining.py:414: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/bert/run_pretraining.py:418: The name tf.gfile.Glob is deprecated. Please use tf.io.gfile.glob instead.\n",
            "\n",
            "W1019 15:06:27.595638 140597344753536 module_wrapper.py:139] From /content/bert/run_pretraining.py:418: The name tf.gfile.Glob is deprecated. Please use tf.io.gfile.glob instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/bert/run_pretraining.py:420: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
            "\n",
            "W1019 15:06:27.596944 140597344753536 module_wrapper.py:139] From /content/bert/run_pretraining.py:420: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
            "\n",
            "INFO:tensorflow:*** Input Files ***\n",
            "I1019 15:06:27.597111 140597344753536 run_pretraining.py:420] *** Input Files ***\n",
            "INFO:tensorflow:  /content/wiki_20190620_small_64_tf.record\n",
            "I1019 15:06:27.597246 140597344753536 run_pretraining.py:422]   /content/wiki_20190620_small_64_tf.record\n",
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "W1019 15:06:27.597485 140597344753536 lazy_loader.py:50] \n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "I1019 15:06:28.590564 140597344753536 utils.py:141] NumExpr defaulting to 2 threads.\n",
            "WARNING:tensorflow:Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7fdef8b78f28>) includes params argument, but params are not passed to Estimator.\n",
            "W1019 15:06:29.716947 140597344753536 estimator.py:1994] Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7fdef8b78f28>) includes params argument, but params are not passed to Estimator.\n",
            "INFO:tensorflow:Using config: {'_model_dir': '/content/my_pretrained_model', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 5, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': None, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fdef8b2a208>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_tpu_config': TPUConfig(iterations_per_loop=1000, num_shards=8, num_cores_per_replica=None, per_host_input_for_training=3, tpu_job_name=None, initial_infeed_sleep_secs=None, input_partition_dims=None, eval_training_input_configuration=2, experimental_host_call_every_n_steps=1), '_cluster': None}\n",
            "I1019 15:06:29.718511 140597344753536 estimator.py:212] Using config: {'_model_dir': '/content/my_pretrained_model', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 5, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': None, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fdef8b2a208>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_tpu_config': TPUConfig(iterations_per_loop=1000, num_shards=8, num_cores_per_replica=None, per_host_input_for_training=3, tpu_job_name=None, initial_infeed_sleep_secs=None, input_partition_dims=None, eval_training_input_configuration=2, experimental_host_call_every_n_steps=1), '_cluster': None}\n",
            "INFO:tensorflow:_TPUContext: eval_on_tpu True\n",
            "I1019 15:06:29.718903 140597344753536 tpu_context.py:220] _TPUContext: eval_on_tpu True\n",
            "WARNING:tensorflow:eval_on_tpu ignored because use_tpu is False.\n",
            "W1019 15:06:29.719520 140597344753536 tpu_context.py:222] eval_on_tpu ignored because use_tpu is False.\n",
            "INFO:tensorflow:***** Running training *****\n",
            "I1019 15:06:29.719702 140597344753536 run_pretraining.py:459] ***** Running training *****\n",
            "INFO:tensorflow:  Batch size = 4\n",
            "I1019 15:06:29.719865 140597344753536 run_pretraining.py:460]   Batch size = 4\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "W1019 15:06:29.733800 140597344753536 deprecation.py:506] From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
            "W1019 15:06:29.734407 140597344753536 deprecation.py:323] From /tensorflow-1.15.2/python3.6/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
            "WARNING:tensorflow:From /content/bert/run_pretraining.py:337: The name tf.FixedLenFeature is deprecated. Please use tf.io.FixedLenFeature instead.\n",
            "\n",
            "W1019 15:06:29.748390 140597344753536 module_wrapper.py:139] From /content/bert/run_pretraining.py:337: The name tf.FixedLenFeature is deprecated. Please use tf.io.FixedLenFeature instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/bert/run_pretraining.py:368: parallel_interleave (from tensorflow.contrib.data.python.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.experimental.parallel_interleave(...)`.\n",
            "W1019 15:06:29.754759 140597344753536 deprecation.py:323] From /content/bert/run_pretraining.py:368: parallel_interleave (from tensorflow.contrib.data.python.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.experimental.parallel_interleave(...)`.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/contrib/data/python/ops/interleave_ops.py:77: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.\n",
            "W1019 15:06:29.754967 140597344753536 deprecation.py:323] From /tensorflow-1.15.2/python3.6/tensorflow_core/contrib/data/python/ops/interleave_ops.py:77: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.\n",
            "WARNING:tensorflow:From /content/bert/run_pretraining.py:385: map_and_batch (from tensorflow.contrib.data.python.ops.batching) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.experimental.map_and_batch(...)`.\n",
            "W1019 15:06:29.780780 140597344753536 deprecation.py:323] From /content/bert/run_pretraining.py:385: map_and_batch (from tensorflow.contrib.data.python.ops.batching) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.experimental.map_and_batch(...)`.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/contrib/data/python/ops/batching.py:276: map_and_batch (from tensorflow.python.data.experimental.ops.batching) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map(map_func, num_parallel_calls)` followed by `tf.data.Dataset.batch(batch_size, drop_remainder)`. Static tf.data optimizations will take care of using the fused implementation.\n",
            "W1019 15:06:29.781031 140597344753536 deprecation.py:323] From /tensorflow-1.15.2/python3.6/tensorflow_core/contrib/data/python/ops/batching.py:276: map_and_batch (from tensorflow.python.data.experimental.ops.batching) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map(map_func, num_parallel_calls)` followed by `tf.data.Dataset.batch(batch_size, drop_remainder)`. Static tf.data optimizations will take care of using the fused implementation.\n",
            "WARNING:tensorflow:Entity <function input_fn_builder.<locals>.input_fn.<locals>.<lambda> at 0x7fdef77c5510> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Str'\n",
            "W1019 15:06:29.792666 140597344753536 ag_logging.py:146] Entity <function input_fn_builder.<locals>.input_fn.<locals>.<lambda> at 0x7fdef77c5510> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Str'\n",
            "WARNING:tensorflow:From /content/bert/run_pretraining.py:393: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.\n",
            "\n",
            "W1019 15:06:29.792915 140597344753536 module_wrapper.py:139] From /content/bert/run_pretraining.py:393: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/bert/run_pretraining.py:400: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "W1019 15:06:29.805429 140597344753536 deprecation.py:323] From /content/bert/run_pretraining.py:400: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I1019 15:06:29.833414 140597344753536 estimator.py:1148] Calling model_fn.\n",
            "INFO:tensorflow:Running train on CPU\n",
            "I1019 15:06:29.833680 140597344753536 tpu_estimator.py:3124] Running train on CPU\n",
            "INFO:tensorflow:*** Features ***\n",
            "I1019 15:06:29.834081 140597344753536 run_pretraining.py:117] *** Features ***\n",
            "INFO:tensorflow:  name = input_ids, shape = (4, 64)\n",
            "I1019 15:06:29.834288 140597344753536 run_pretraining.py:119]   name = input_ids, shape = (4, 64)\n",
            "INFO:tensorflow:  name = input_mask, shape = (4, 64)\n",
            "I1019 15:06:29.834495 140597344753536 run_pretraining.py:119]   name = input_mask, shape = (4, 64)\n",
            "INFO:tensorflow:  name = masked_lm_ids, shape = (4, 20)\n",
            "I1019 15:06:29.834671 140597344753536 run_pretraining.py:119]   name = masked_lm_ids, shape = (4, 20)\n",
            "INFO:tensorflow:  name = masked_lm_positions, shape = (4, 20)\n",
            "I1019 15:06:29.834859 140597344753536 run_pretraining.py:119]   name = masked_lm_positions, shape = (4, 20)\n",
            "INFO:tensorflow:  name = masked_lm_weights, shape = (4, 20)\n",
            "I1019 15:06:29.835016 140597344753536 run_pretraining.py:119]   name = masked_lm_weights, shape = (4, 20)\n",
            "INFO:tensorflow:  name = next_sentence_labels, shape = (4, 1)\n",
            "I1019 15:06:29.835187 140597344753536 run_pretraining.py:119]   name = next_sentence_labels, shape = (4, 1)\n",
            "INFO:tensorflow:  name = segment_ids, shape = (4, 64)\n",
            "I1019 15:06:29.835339 140597344753536 run_pretraining.py:119]   name = segment_ids, shape = (4, 64)\n",
            "WARNING:tensorflow:From /content/bert/modeling.py:171: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n",
            "W1019 15:06:29.835662 140597344753536 module_wrapper.py:139] From /content/bert/modeling.py:171: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/bert/modeling.py:409: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
            "\n",
            "W1019 15:06:29.837229 140597344753536 module_wrapper.py:139] From /content/bert/modeling.py:409: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/bert/modeling.py:490: The name tf.assert_less_equal is deprecated. Please use tf.compat.v1.assert_less_equal instead.\n",
            "\n",
            "W1019 15:06:29.863685 140597344753536 module_wrapper.py:139] From /content/bert/modeling.py:490: The name tf.assert_less_equal is deprecated. Please use tf.compat.v1.assert_less_equal instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/bert/modeling.py:358: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "W1019 15:06:29.903305 140597344753536 deprecation.py:506] From /content/bert/modeling.py:358: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /content/bert/modeling.py:671: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.Dense instead.\n",
            "W1019 15:06:29.919422 140597344753536 deprecation.py:323] From /content/bert/modeling.py:671: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.Dense instead.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/layers/core.py:187: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "W1019 15:06:29.920938 140597344753536 deprecation.py:323] From /tensorflow-1.15.2/python3.6/tensorflow_core/python/layers/core.py:187: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "WARNING:tensorflow:From /content/bert/run_pretraining.py:150: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.\n",
            "\n",
            "W1019 15:06:32.278815 140597344753536 module_wrapper.py:139] From /content/bert/run_pretraining.py:150: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.\n",
            "\n",
            "INFO:tensorflow:**** Trainable Variables ****\n",
            "I1019 15:06:32.279163 140597344753536 run_pretraining.py:167] **** Trainable Variables ****\n",
            "INFO:tensorflow:  name = bert/embeddings/word_embeddings:0, shape = (967, 768)\n",
            "I1019 15:06:32.279403 140597344753536 run_pretraining.py:173]   name = bert/embeddings/word_embeddings:0, shape = (967, 768)\n",
            "INFO:tensorflow:  name = bert/embeddings/token_type_embeddings:0, shape = (2, 768)\n",
            "I1019 15:06:32.279748 140597344753536 run_pretraining.py:173]   name = bert/embeddings/token_type_embeddings:0, shape = (2, 768)\n",
            "INFO:tensorflow:  name = bert/embeddings/position_embeddings:0, shape = (512, 768)\n",
            "I1019 15:06:32.280021 140597344753536 run_pretraining.py:173]   name = bert/embeddings/position_embeddings:0, shape = (512, 768)\n",
            "INFO:tensorflow:  name = bert/embeddings/LayerNorm/beta:0, shape = (768,)\n",
            "I1019 15:06:32.280285 140597344753536 run_pretraining.py:173]   name = bert/embeddings/LayerNorm/beta:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/embeddings/LayerNorm/gamma:0, shape = (768,)\n",
            "I1019 15:06:32.280561 140597344753536 run_pretraining.py:173]   name = bert/embeddings/LayerNorm/gamma:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/query/kernel:0, shape = (768, 768)\n",
            "I1019 15:06:32.280809 140597344753536 run_pretraining.py:173]   name = bert/encoder/layer_0/attention/self/query/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/query/bias:0, shape = (768,)\n",
            "I1019 15:06:32.281061 140597344753536 run_pretraining.py:173]   name = bert/encoder/layer_0/attention/self/query/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/key/kernel:0, shape = (768, 768)\n",
            "I1019 15:06:32.281283 140597344753536 run_pretraining.py:173]   name = bert/encoder/layer_0/attention/self/key/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/key/bias:0, shape = (768,)\n",
            "I1019 15:06:32.281547 140597344753536 run_pretraining.py:173]   name = bert/encoder/layer_0/attention/self/key/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/value/kernel:0, shape = (768, 768)\n",
            "I1019 15:06:32.281788 140597344753536 run_pretraining.py:173]   name = bert/encoder/layer_0/attention/self/value/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/value/bias:0, shape = (768,)\n",
            "I1019 15:06:32.282039 140597344753536 run_pretraining.py:173]   name = bert/encoder/layer_0/attention/self/value/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/dense/kernel:0, shape = (768, 768)\n",
            "I1019 15:06:32.282258 140597344753536 run_pretraining.py:173]   name = bert/encoder/layer_0/attention/output/dense/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/dense/bias:0, shape = (768,)\n",
            "I1019 15:06:32.282529 140597344753536 run_pretraining.py:173]   name = bert/encoder/layer_0/attention/output/dense/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/LayerNorm/beta:0, shape = (768,)\n",
            "I1019 15:06:32.282744 140597344753536 run_pretraining.py:173]   name = bert/encoder/layer_0/attention/output/LayerNorm/beta:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
            "I1019 15:06:32.282970 140597344753536 run_pretraining.py:173]   name = bert/encoder/layer_0/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/intermediate/dense/kernel:0, shape = (768, 3072)\n",
            "I1019 15:06:32.283186 140597344753536 run_pretraining.py:173]   name = bert/encoder/layer_0/intermediate/dense/kernel:0, shape = (768, 3072)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/intermediate/dense/bias:0, shape = (3072,)\n",
            "I1019 15:06:32.283418 140597344753536 run_pretraining.py:173]   name = bert/encoder/layer_0/intermediate/dense/bias:0, shape = (3072,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/output/dense/kernel:0, shape = (3072, 768)\n",
            "I1019 15:06:32.283675 140597344753536 run_pretraining.py:173]   name = bert/encoder/layer_0/output/dense/kernel:0, shape = (3072, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/output/dense/bias:0, shape = (768,)\n",
            "I1019 15:06:32.283924 140597344753536 run_pretraining.py:173]   name = bert/encoder/layer_0/output/dense/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/output/LayerNorm/beta:0, shape = (768,)\n",
            "I1019 15:06:32.284140 140597344753536 run_pretraining.py:173]   name = bert/encoder/layer_0/output/LayerNorm/beta:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/output/LayerNorm/gamma:0, shape = (768,)\n",
            "I1019 15:06:32.284385 140597344753536 run_pretraining.py:173]   name = bert/encoder/layer_0/output/LayerNorm/gamma:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/query/kernel:0, shape = (768, 768)\n",
            "I1019 15:06:32.284637 140597344753536 run_pretraining.py:173]   name = bert/encoder/layer_1/attention/self/query/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/query/bias:0, shape = (768,)\n",
            "I1019 15:06:32.284893 140597344753536 run_pretraining.py:173]   name = bert/encoder/layer_1/attention/self/query/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/key/kernel:0, shape = (768, 768)\n",
            "I1019 15:06:32.285151 140597344753536 run_pretraining.py:173]   name = bert/encoder/layer_1/attention/self/key/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/key/bias:0, shape = (768,)\n",
            "I1019 15:06:32.285408 140597344753536 run_pretraining.py:173]   name = bert/encoder/layer_1/attention/self/key/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/value/kernel:0, shape = (768, 768)\n",
            "I1019 15:06:32.285668 140597344753536 run_pretraining.py:173]   name = bert/encoder/layer_1/attention/self/value/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/value/bias:0, shape = (768,)\n",
            "I1019 15:06:32.285919 140597344753536 run_pretraining.py:173]   name = bert/encoder/layer_1/attention/self/value/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/dense/kernel:0, shape = (768, 768)\n",
            "I1019 15:06:32.286156 140597344753536 run_pretraining.py:173]   name = bert/encoder/layer_1/attention/output/dense/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/dense/bias:0, shape = (768,)\n",
            "I1019 15:06:32.286397 140597344753536 run_pretraining.py:173]   name = bert/encoder/layer_1/attention/output/dense/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/LayerNorm/beta:0, shape = (768,)\n",
            "I1019 15:06:32.286749 140597344753536 run_pretraining.py:173]   name = bert/encoder/layer_1/attention/output/LayerNorm/beta:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
            "I1019 15:06:32.287013 140597344753536 run_pretraining.py:173]   name = bert/encoder/layer_1/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/intermediate/dense/kernel:0, shape = (768, 3072)\n",
            "I1019 15:06:32.287256 140597344753536 run_pretraining.py:173]   name = bert/encoder/layer_1/intermediate/dense/kernel:0, shape = (768, 3072)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/intermediate/dense/bias:0, shape = (3072,)\n",
            "I1019 15:06:32.287526 140597344753536 run_pretraining.py:173]   name = bert/encoder/layer_1/intermediate/dense/bias:0, shape = (3072,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/output/dense/kernel:0, shape = (3072, 768)\n",
            "I1019 15:06:32.287762 140597344753536 run_pretraining.py:173]   name = bert/encoder/layer_1/output/dense/kernel:0, shape = (3072, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/output/dense/bias:0, shape = (768,)\n",
            "I1019 15:06:32.288030 140597344753536 run_pretraining.py:173]   name = bert/encoder/layer_1/output/dense/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/output/LayerNorm/beta:0, shape = (768,)\n",
            "I1019 15:06:32.288302 140597344753536 run_pretraining.py:173]   name = bert/encoder/layer_1/output/LayerNorm/beta:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/output/LayerNorm/gamma:0, shape = (768,)\n",
            "I1019 15:06:32.288553 140597344753536 run_pretraining.py:173]   name = bert/encoder/layer_1/output/LayerNorm/gamma:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/query/kernel:0, shape = (768, 768)\n",
            "I1019 15:06:32.288771 140597344753536 run_pretraining.py:173]   name = bert/encoder/layer_2/attention/self/query/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/query/bias:0, shape = (768,)\n",
            "I1019 15:06:32.289042 140597344753536 run_pretraining.py:173]   name = bert/encoder/layer_2/attention/self/query/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/key/kernel:0, shape = (768, 768)\n",
            "I1019 15:06:32.289269 140597344753536 run_pretraining.py:173]   name = bert/encoder/layer_2/attention/self/key/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/key/bias:0, shape = (768,)\n",
            "I1019 15:06:32.289524 140597344753536 run_pretraining.py:173]   name = bert/encoder/layer_2/attention/self/key/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/value/kernel:0, shape = (768, 768)\n",
            "I1019 15:06:32.289750 140597344753536 run_pretraining.py:173]   name = bert/encoder/layer_2/attention/self/value/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/value/bias:0, shape = (768,)\n",
            "I1019 15:06:32.289989 140597344753536 run_pretraining.py:173]   name = bert/encoder/layer_2/attention/self/value/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/dense/kernel:0, shape = (768, 768)\n",
            "I1019 15:06:32.290212 140597344753536 run_pretraining.py:173]   name = bert/encoder/layer_2/attention/output/dense/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/dense/bias:0, shape = (768,)\n",
            "I1019 15:06:32.290461 140597344753536 run_pretraining.py:173]   name = bert/encoder/layer_2/attention/output/dense/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/LayerNorm/beta:0, shape = (768,)\n",
            "I1019 15:06:32.290700 140597344753536 run_pretraining.py:173]   name = bert/encoder/layer_2/attention/output/LayerNorm/beta:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
            "I1019 15:06:32.290931 140597344753536 run_pretraining.py:173]   name = bert/encoder/layer_2/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/intermediate/dense/kernel:0, shape = (768, 3072)\n",
            "I1019 15:06:32.291165 140597344753536 run_pretraining.py:173]   name = bert/encoder/layer_2/intermediate/dense/kernel:0, shape = (768, 3072)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/intermediate/dense/bias:0, shape = (3072,)\n",
            "I1019 15:06:32.291399 140597344753536 run_pretraining.py:173]   name = bert/encoder/layer_2/intermediate/dense/bias:0, shape = (3072,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/output/dense/kernel:0, shape = (3072, 768)\n",
            "I1019 15:06:32.291658 140597344753536 run_pretraining.py:173]   name = bert/encoder/layer_2/output/dense/kernel:0, shape = (3072, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/output/dense/bias:0, shape = (768,)\n",
            "I1019 15:06:32.291895 140597344753536 run_pretraining.py:173]   name = bert/encoder/layer_2/output/dense/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/output/LayerNorm/beta:0, shape = (768,)\n",
            "I1019 15:06:32.292174 140597344753536 run_pretraining.py:173]   name = bert/encoder/layer_2/output/LayerNorm/beta:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/output/LayerNorm/gamma:0, shape = (768,)\n",
            "I1019 15:06:32.292397 140597344753536 run_pretraining.py:173]   name = bert/encoder/layer_2/output/LayerNorm/gamma:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/query/kernel:0, shape = (768, 768)\n",
            "I1019 15:06:32.292690 140597344753536 run_pretraining.py:173]   name = bert/encoder/layer_3/attention/self/query/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/query/bias:0, shape = (768,)\n",
            "I1019 15:06:32.292970 140597344753536 run_pretraining.py:173]   name = bert/encoder/layer_3/attention/self/query/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/key/kernel:0, shape = (768, 768)\n",
            "I1019 15:06:32.293215 140597344753536 run_pretraining.py:173]   name = bert/encoder/layer_3/attention/self/key/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/key/bias:0, shape = (768,)\n",
            "I1019 15:06:32.293520 140597344753536 run_pretraining.py:173]   name = bert/encoder/layer_3/attention/self/key/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/value/kernel:0, shape = (768, 768)\n",
            "I1019 15:06:32.293765 140597344753536 run_pretraining.py:173]   name = bert/encoder/layer_3/attention/self/value/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/value/bias:0, shape = (768,)\n",
            "I1019 15:06:32.294053 140597344753536 run_pretraining.py:173]   name = bert/encoder/layer_3/attention/self/value/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/dense/kernel:0, shape = (768, 768)\n",
            "I1019 15:06:32.294297 140597344753536 run_pretraining.py:173]   name = bert/encoder/layer_3/attention/output/dense/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/dense/bias:0, shape = (768,)\n",
            "I1019 15:06:32.294556 140597344753536 run_pretraining.py:173]   name = bert/encoder/layer_3/attention/output/dense/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/LayerNorm/beta:0, shape = (768,)\n",
            "I1019 15:06:32.294826 140597344753536 run_pretraining.py:173]   name = bert/encoder/layer_3/attention/output/LayerNorm/beta:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
            "I1019 15:06:32.295048 140597344753536 run_pretraining.py:173]   name = bert/encoder/layer_3/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/intermediate/dense/kernel:0, shape = (768, 3072)\n",
            "I1019 15:06:32.295245 140597344753536 run_pretraining.py:173]   name = bert/encoder/layer_3/intermediate/dense/kernel:0, shape = (768, 3072)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/intermediate/dense/bias:0, shape = (3072,)\n",
            "I1019 15:06:32.295476 140597344753536 run_pretraining.py:173]   name = bert/encoder/layer_3/intermediate/dense/bias:0, shape = (3072,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/output/dense/kernel:0, shape = (3072, 768)\n",
            "I1019 15:06:32.295694 140597344753536 run_pretraining.py:173]   name = bert/encoder/layer_3/output/dense/kernel:0, shape = (3072, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/output/dense/bias:0, shape = (768,)\n",
            "I1019 15:06:32.295917 140597344753536 run_pretraining.py:173]   name = bert/encoder/layer_3/output/dense/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/output/LayerNorm/beta:0, shape = (768,)\n",
            "I1019 15:06:32.296113 140597344753536 run_pretraining.py:173]   name = bert/encoder/layer_3/output/LayerNorm/beta:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/output/LayerNorm/gamma:0, shape = (768,)\n",
            "I1019 15:06:32.296305 140597344753536 run_pretraining.py:173]   name = bert/encoder/layer_3/output/LayerNorm/gamma:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/query/kernel:0, shape = (768, 768)\n",
            "I1019 15:06:32.296519 140597344753536 run_pretraining.py:173]   name = bert/encoder/layer_4/attention/self/query/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/query/bias:0, shape = (768,)\n",
            "I1019 15:06:32.296746 140597344753536 run_pretraining.py:173]   name = bert/encoder/layer_4/attention/self/query/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/key/kernel:0, shape = (768, 768)\n",
            "I1019 15:06:32.296955 140597344753536 run_pretraining.py:173]   name = bert/encoder/layer_4/attention/self/key/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/key/bias:0, shape = (768,)\n",
            "I1019 15:06:32.297152 140597344753536 run_pretraining.py:173]   name = bert/encoder/layer_4/attention/self/key/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/value/kernel:0, shape = (768, 768)\n",
            "I1019 15:06:32.297343 140597344753536 run_pretraining.py:173]   name = bert/encoder/layer_4/attention/self/value/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/value/bias:0, shape = (768,)\n",
            "I1019 15:06:32.297560 140597344753536 run_pretraining.py:173]   name = bert/encoder/layer_4/attention/self/value/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/attention/output/dense/kernel:0, shape = (768, 768)\n",
            "I1019 15:06:32.297759 140597344753536 run_pretraining.py:173]   name = bert/encoder/layer_4/attention/output/dense/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/attention/output/dense/bias:0, shape = (768,)\n",
            "I1019 15:06:32.297964 140597344753536 run_pretraining.py:173]   name = bert/encoder/layer_4/attention/output/dense/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/attention/output/LayerNorm/beta:0, shape = (768,)\n",
            "I1019 15:06:32.298159 140597344753536 run_pretraining.py:173]   name = bert/encoder/layer_4/attention/output/LayerNorm/beta:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
            "I1019 15:06:32.352329 140597344753536 run_pretraining.py:173]   name = bert/encoder/layer_4/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/intermediate/dense/kernel:0, shape = (768, 3072)\n",
            "I1019 15:06:32.352610 140597344753536 run_pretraining.py:173]   name = bert/encoder/layer_4/intermediate/dense/kernel:0, shape = (768, 3072)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/intermediate/dense/bias:0, shape = (3072,)\n",
            "I1019 15:06:32.352828 140597344753536 run_pretraining.py:173]   name = bert/encoder/layer_4/intermediate/dense/bias:0, shape = (3072,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/output/dense/kernel:0, shape = (3072, 768)\n",
            "I1019 15:06:32.353035 140597344753536 run_pretraining.py:173]   name = bert/encoder/layer_4/output/dense/kernel:0, shape = (3072, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/output/dense/bias:0, shape = (768,)\n",
            "I1019 15:06:32.353281 140597344753536 run_pretraining.py:173]   name = bert/encoder/layer_4/output/dense/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/output/LayerNorm/beta:0, shape = (768,)\n",
            "I1019 15:06:32.353550 140597344753536 run_pretraining.py:173]   name = bert/encoder/layer_4/output/LayerNorm/beta:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/output/LayerNorm/gamma:0, shape = (768,)\n",
            "I1019 15:06:32.353786 140597344753536 run_pretraining.py:173]   name = bert/encoder/layer_4/output/LayerNorm/gamma:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/query/kernel:0, shape = (768, 768)\n",
            "I1019 15:06:32.354056 140597344753536 run_pretraining.py:173]   name = bert/encoder/layer_5/attention/self/query/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/query/bias:0, shape = (768,)\n",
            "I1019 15:06:32.354302 140597344753536 run_pretraining.py:173]   name = bert/encoder/layer_5/attention/self/query/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/key/kernel:0, shape = (768, 768)\n",
            "I1019 15:06:32.354565 140597344753536 run_pretraining.py:173]   name = bert/encoder/layer_5/attention/self/key/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/key/bias:0, shape = (768,)\n",
            "I1019 15:06:32.354801 140597344753536 run_pretraining.py:173]   name = bert/encoder/layer_5/attention/self/key/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/value/kernel:0, shape = (768, 768)\n",
            "I1019 15:06:32.355077 140597344753536 run_pretraining.py:173]   name = bert/encoder/layer_5/attention/self/value/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/value/bias:0, shape = (768,)\n",
            "I1019 15:06:32.355345 140597344753536 run_pretraining.py:173]   name = bert/encoder/layer_5/attention/self/value/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/attention/output/dense/kernel:0, shape = (768, 768)\n",
            "I1019 15:06:32.355596 140597344753536 run_pretraining.py:173]   name = bert/encoder/layer_5/attention/output/dense/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/attention/output/dense/bias:0, shape = (768,)\n",
            "I1019 15:06:32.355897 140597344753536 run_pretraining.py:173]   name = bert/encoder/layer_5/attention/output/dense/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/attention/output/LayerNorm/beta:0, shape = (768,)\n",
            "I1019 15:06:32.356133 140597344753536 run_pretraining.py:173]   name = bert/encoder/layer_5/attention/output/LayerNorm/beta:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
            "I1019 15:06:32.356353 140597344753536 run_pretraining.py:173]   name = bert/encoder/layer_5/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/intermediate/dense/kernel:0, shape = (768, 3072)\n",
            "I1019 15:06:32.356604 140597344753536 run_pretraining.py:173]   name = bert/encoder/layer_5/intermediate/dense/kernel:0, shape = (768, 3072)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/intermediate/dense/bias:0, shape = (3072,)\n",
            "I1019 15:06:32.356917 140597344753536 run_pretraining.py:173]   name = bert/encoder/layer_5/intermediate/dense/bias:0, shape = (3072,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/output/dense/kernel:0, shape = (3072, 768)\n",
            "I1019 15:06:32.357144 140597344753536 run_pretraining.py:173]   name = bert/encoder/layer_5/output/dense/kernel:0, shape = (3072, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/output/dense/bias:0, shape = (768,)\n",
            "I1019 15:06:32.357475 140597344753536 run_pretraining.py:173]   name = bert/encoder/layer_5/output/dense/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/output/LayerNorm/beta:0, shape = (768,)\n",
            "I1019 15:06:32.357706 140597344753536 run_pretraining.py:173]   name = bert/encoder/layer_5/output/LayerNorm/beta:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/output/LayerNorm/gamma:0, shape = (768,)\n",
            "I1019 15:06:32.357943 140597344753536 run_pretraining.py:173]   name = bert/encoder/layer_5/output/LayerNorm/gamma:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/query/kernel:0, shape = (768, 768)\n",
            "I1019 15:06:32.358197 140597344753536 run_pretraining.py:173]   name = bert/encoder/layer_6/attention/self/query/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/query/bias:0, shape = (768,)\n",
            "I1019 15:06:32.358439 140597344753536 run_pretraining.py:173]   name = bert/encoder/layer_6/attention/self/query/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/key/kernel:0, shape = (768, 768)\n",
            "I1019 15:06:32.358688 140597344753536 run_pretraining.py:173]   name = bert/encoder/layer_6/attention/self/key/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/key/bias:0, shape = (768,)\n",
            "I1019 15:06:32.358918 140597344753536 run_pretraining.py:173]   name = bert/encoder/layer_6/attention/self/key/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/value/kernel:0, shape = (768, 768)\n",
            "I1019 15:06:32.359139 140597344753536 run_pretraining.py:173]   name = bert/encoder/layer_6/attention/self/value/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/value/bias:0, shape = (768,)\n",
            "I1019 15:06:32.359369 140597344753536 run_pretraining.py:173]   name = bert/encoder/layer_6/attention/self/value/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/attention/output/dense/kernel:0, shape = (768, 768)\n",
            "I1019 15:06:32.359624 140597344753536 run_pretraining.py:173]   name = bert/encoder/layer_6/attention/output/dense/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/attention/output/dense/bias:0, shape = (768,)\n",
            "I1019 15:06:32.359868 140597344753536 run_pretraining.py:173]   name = bert/encoder/layer_6/attention/output/dense/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/attention/output/LayerNorm/beta:0, shape = (768,)\n",
            "I1019 15:06:32.360113 140597344753536 run_pretraining.py:173]   name = bert/encoder/layer_6/attention/output/LayerNorm/beta:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
            "I1019 15:06:32.360407 140597344753536 run_pretraining.py:173]   name = bert/encoder/layer_6/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/intermediate/dense/kernel:0, shape = (768, 3072)\n",
            "I1019 15:06:32.360674 140597344753536 run_pretraining.py:173]   name = bert/encoder/layer_6/intermediate/dense/kernel:0, shape = (768, 3072)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/intermediate/dense/bias:0, shape = (3072,)\n",
            "I1019 15:06:32.360899 140597344753536 run_pretraining.py:173]   name = bert/encoder/layer_6/intermediate/dense/bias:0, shape = (3072,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/output/dense/kernel:0, shape = (3072, 768)\n",
            "I1019 15:06:32.361134 140597344753536 run_pretraining.py:173]   name = bert/encoder/layer_6/output/dense/kernel:0, shape = (3072, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/output/dense/bias:0, shape = (768,)\n",
            "I1019 15:06:32.361371 140597344753536 run_pretraining.py:173]   name = bert/encoder/layer_6/output/dense/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/output/LayerNorm/beta:0, shape = (768,)\n",
            "I1019 15:06:32.361622 140597344753536 run_pretraining.py:173]   name = bert/encoder/layer_6/output/LayerNorm/beta:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/output/LayerNorm/gamma:0, shape = (768,)\n",
            "I1019 15:06:32.361880 140597344753536 run_pretraining.py:173]   name = bert/encoder/layer_6/output/LayerNorm/gamma:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/query/kernel:0, shape = (768, 768)\n",
            "I1019 15:06:32.362227 140597344753536 run_pretraining.py:173]   name = bert/encoder/layer_7/attention/self/query/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/query/bias:0, shape = (768,)\n",
            "I1019 15:06:32.362621 140597344753536 run_pretraining.py:173]   name = bert/encoder/layer_7/attention/self/query/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/key/kernel:0, shape = (768, 768)\n",
            "I1019 15:06:32.362886 140597344753536 run_pretraining.py:173]   name = bert/encoder/layer_7/attention/self/key/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/key/bias:0, shape = (768,)\n",
            "I1019 15:06:32.363133 140597344753536 run_pretraining.py:173]   name = bert/encoder/layer_7/attention/self/key/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/value/kernel:0, shape = (768, 768)\n",
            "I1019 15:06:32.363442 140597344753536 run_pretraining.py:173]   name = bert/encoder/layer_7/attention/self/value/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/value/bias:0, shape = (768,)\n",
            "I1019 15:06:32.363727 140597344753536 run_pretraining.py:173]   name = bert/encoder/layer_7/attention/self/value/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/attention/output/dense/kernel:0, shape = (768, 768)\n",
            "I1019 15:06:32.363952 140597344753536 run_pretraining.py:173]   name = bert/encoder/layer_7/attention/output/dense/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/attention/output/dense/bias:0, shape = (768,)\n",
            "I1019 15:06:32.364217 140597344753536 run_pretraining.py:173]   name = bert/encoder/layer_7/attention/output/dense/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/attention/output/LayerNorm/beta:0, shape = (768,)\n",
            "I1019 15:06:32.364499 140597344753536 run_pretraining.py:173]   name = bert/encoder/layer_7/attention/output/LayerNorm/beta:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
            "I1019 15:06:32.364722 140597344753536 run_pretraining.py:173]   name = bert/encoder/layer_7/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/intermediate/dense/kernel:0, shape = (768, 3072)\n",
            "I1019 15:06:32.365005 140597344753536 run_pretraining.py:173]   name = bert/encoder/layer_7/intermediate/dense/kernel:0, shape = (768, 3072)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/intermediate/dense/bias:0, shape = (3072,)\n",
            "I1019 15:06:32.365267 140597344753536 run_pretraining.py:173]   name = bert/encoder/layer_7/intermediate/dense/bias:0, shape = (3072,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/output/dense/kernel:0, shape = (3072, 768)\n",
            "I1019 15:06:32.365525 140597344753536 run_pretraining.py:173]   name = bert/encoder/layer_7/output/dense/kernel:0, shape = (3072, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/output/dense/bias:0, shape = (768,)\n",
            "I1019 15:06:32.365765 140597344753536 run_pretraining.py:173]   name = bert/encoder/layer_7/output/dense/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/output/LayerNorm/beta:0, shape = (768,)\n",
            "I1019 15:06:32.365989 140597344753536 run_pretraining.py:173]   name = bert/encoder/layer_7/output/LayerNorm/beta:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/output/LayerNorm/gamma:0, shape = (768,)\n",
            "I1019 15:06:32.366254 140597344753536 run_pretraining.py:173]   name = bert/encoder/layer_7/output/LayerNorm/gamma:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/query/kernel:0, shape = (768, 768)\n",
            "I1019 15:06:32.366512 140597344753536 run_pretraining.py:173]   name = bert/encoder/layer_8/attention/self/query/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/query/bias:0, shape = (768,)\n",
            "I1019 15:06:32.366786 140597344753536 run_pretraining.py:173]   name = bert/encoder/layer_8/attention/self/query/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/key/kernel:0, shape = (768, 768)\n",
            "I1019 15:06:32.367022 140597344753536 run_pretraining.py:173]   name = bert/encoder/layer_8/attention/self/key/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/key/bias:0, shape = (768,)\n",
            "I1019 15:06:32.367261 140597344753536 run_pretraining.py:173]   name = bert/encoder/layer_8/attention/self/key/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/value/kernel:0, shape = (768, 768)\n",
            "I1019 15:06:32.367517 140597344753536 run_pretraining.py:173]   name = bert/encoder/layer_8/attention/self/value/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/value/bias:0, shape = (768,)\n",
            "I1019 15:06:32.367769 140597344753536 run_pretraining.py:173]   name = bert/encoder/layer_8/attention/self/value/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/attention/output/dense/kernel:0, shape = (768, 768)\n",
            "I1019 15:06:32.368063 140597344753536 run_pretraining.py:173]   name = bert/encoder/layer_8/attention/output/dense/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/attention/output/dense/bias:0, shape = (768,)\n",
            "I1019 15:06:32.368299 140597344753536 run_pretraining.py:173]   name = bert/encoder/layer_8/attention/output/dense/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/attention/output/LayerNorm/beta:0, shape = (768,)\n",
            "I1019 15:06:32.368557 140597344753536 run_pretraining.py:173]   name = bert/encoder/layer_8/attention/output/LayerNorm/beta:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
            "I1019 15:06:32.368781 140597344753536 run_pretraining.py:173]   name = bert/encoder/layer_8/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/intermediate/dense/kernel:0, shape = (768, 3072)\n",
            "I1019 15:06:32.369003 140597344753536 run_pretraining.py:173]   name = bert/encoder/layer_8/intermediate/dense/kernel:0, shape = (768, 3072)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/intermediate/dense/bias:0, shape = (3072,)\n",
            "I1019 15:06:32.369237 140597344753536 run_pretraining.py:173]   name = bert/encoder/layer_8/intermediate/dense/bias:0, shape = (3072,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/output/dense/kernel:0, shape = (3072, 768)\n",
            "I1019 15:06:32.369502 140597344753536 run_pretraining.py:173]   name = bert/encoder/layer_8/output/dense/kernel:0, shape = (3072, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/output/dense/bias:0, shape = (768,)\n",
            "I1019 15:06:32.369740 140597344753536 run_pretraining.py:173]   name = bert/encoder/layer_8/output/dense/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/output/LayerNorm/beta:0, shape = (768,)\n",
            "I1019 15:06:32.369976 140597344753536 run_pretraining.py:173]   name = bert/encoder/layer_8/output/LayerNorm/beta:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/output/LayerNorm/gamma:0, shape = (768,)\n",
            "I1019 15:06:32.370197 140597344753536 run_pretraining.py:173]   name = bert/encoder/layer_8/output/LayerNorm/gamma:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/query/kernel:0, shape = (768, 768)\n",
            "I1019 15:06:32.370432 140597344753536 run_pretraining.py:173]   name = bert/encoder/layer_9/attention/self/query/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/query/bias:0, shape = (768,)\n",
            "I1019 15:06:32.370715 140597344753536 run_pretraining.py:173]   name = bert/encoder/layer_9/attention/self/query/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/key/kernel:0, shape = (768, 768)\n",
            "I1019 15:06:32.370940 140597344753536 run_pretraining.py:173]   name = bert/encoder/layer_9/attention/self/key/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/key/bias:0, shape = (768,)\n",
            "I1019 15:06:32.371166 140597344753536 run_pretraining.py:173]   name = bert/encoder/layer_9/attention/self/key/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/value/kernel:0, shape = (768, 768)\n",
            "I1019 15:06:32.371387 140597344753536 run_pretraining.py:173]   name = bert/encoder/layer_9/attention/self/value/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/value/bias:0, shape = (768,)\n",
            "I1019 15:06:32.371647 140597344753536 run_pretraining.py:173]   name = bert/encoder/layer_9/attention/self/value/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/attention/output/dense/kernel:0, shape = (768, 768)\n",
            "I1019 15:06:32.371918 140597344753536 run_pretraining.py:173]   name = bert/encoder/layer_9/attention/output/dense/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/attention/output/dense/bias:0, shape = (768,)\n",
            "I1019 15:06:32.372200 140597344753536 run_pretraining.py:173]   name = bert/encoder/layer_9/attention/output/dense/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/attention/output/LayerNorm/beta:0, shape = (768,)\n",
            "I1019 15:06:32.372503 140597344753536 run_pretraining.py:173]   name = bert/encoder/layer_9/attention/output/LayerNorm/beta:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
            "I1019 15:06:32.372752 140597344753536 run_pretraining.py:173]   name = bert/encoder/layer_9/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/intermediate/dense/kernel:0, shape = (768, 3072)\n",
            "I1019 15:06:32.372989 140597344753536 run_pretraining.py:173]   name = bert/encoder/layer_9/intermediate/dense/kernel:0, shape = (768, 3072)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/intermediate/dense/bias:0, shape = (3072,)\n",
            "I1019 15:06:32.373221 140597344753536 run_pretraining.py:173]   name = bert/encoder/layer_9/intermediate/dense/bias:0, shape = (3072,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/output/dense/kernel:0, shape = (3072, 768)\n",
            "I1019 15:06:32.373469 140597344753536 run_pretraining.py:173]   name = bert/encoder/layer_9/output/dense/kernel:0, shape = (3072, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/output/dense/bias:0, shape = (768,)\n",
            "I1019 15:06:32.373735 140597344753536 run_pretraining.py:173]   name = bert/encoder/layer_9/output/dense/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/output/LayerNorm/beta:0, shape = (768,)\n",
            "I1019 15:06:32.374018 140597344753536 run_pretraining.py:173]   name = bert/encoder/layer_9/output/LayerNorm/beta:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/output/LayerNorm/gamma:0, shape = (768,)\n",
            "I1019 15:06:32.374272 140597344753536 run_pretraining.py:173]   name = bert/encoder/layer_9/output/LayerNorm/gamma:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/query/kernel:0, shape = (768, 768)\n",
            "I1019 15:06:32.374572 140597344753536 run_pretraining.py:173]   name = bert/encoder/layer_10/attention/self/query/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/query/bias:0, shape = (768,)\n",
            "I1019 15:06:32.374818 140597344753536 run_pretraining.py:173]   name = bert/encoder/layer_10/attention/self/query/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/key/kernel:0, shape = (768, 768)\n",
            "I1019 15:06:32.375051 140597344753536 run_pretraining.py:173]   name = bert/encoder/layer_10/attention/self/key/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/key/bias:0, shape = (768,)\n",
            "I1019 15:06:32.375297 140597344753536 run_pretraining.py:173]   name = bert/encoder/layer_10/attention/self/key/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/value/kernel:0, shape = (768, 768)\n",
            "I1019 15:06:32.375572 140597344753536 run_pretraining.py:173]   name = bert/encoder/layer_10/attention/self/value/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/value/bias:0, shape = (768,)\n",
            "I1019 15:06:32.375826 140597344753536 run_pretraining.py:173]   name = bert/encoder/layer_10/attention/self/value/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/attention/output/dense/kernel:0, shape = (768, 768)\n",
            "I1019 15:06:32.376091 140597344753536 run_pretraining.py:173]   name = bert/encoder/layer_10/attention/output/dense/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/attention/output/dense/bias:0, shape = (768,)\n",
            "I1019 15:06:32.376332 140597344753536 run_pretraining.py:173]   name = bert/encoder/layer_10/attention/output/dense/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/attention/output/LayerNorm/beta:0, shape = (768,)\n",
            "I1019 15:06:32.376606 140597344753536 run_pretraining.py:173]   name = bert/encoder/layer_10/attention/output/LayerNorm/beta:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
            "I1019 15:06:32.376851 140597344753536 run_pretraining.py:173]   name = bert/encoder/layer_10/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/intermediate/dense/kernel:0, shape = (768, 3072)\n",
            "I1019 15:06:32.377106 140597344753536 run_pretraining.py:173]   name = bert/encoder/layer_10/intermediate/dense/kernel:0, shape = (768, 3072)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/intermediate/dense/bias:0, shape = (3072,)\n",
            "I1019 15:06:32.377357 140597344753536 run_pretraining.py:173]   name = bert/encoder/layer_10/intermediate/dense/bias:0, shape = (3072,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/output/dense/kernel:0, shape = (3072, 768)\n",
            "I1019 15:06:32.377623 140597344753536 run_pretraining.py:173]   name = bert/encoder/layer_10/output/dense/kernel:0, shape = (3072, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/output/dense/bias:0, shape = (768,)\n",
            "I1019 15:06:32.377882 140597344753536 run_pretraining.py:173]   name = bert/encoder/layer_10/output/dense/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/output/LayerNorm/beta:0, shape = (768,)\n",
            "I1019 15:06:32.378171 140597344753536 run_pretraining.py:173]   name = bert/encoder/layer_10/output/LayerNorm/beta:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/output/LayerNorm/gamma:0, shape = (768,)\n",
            "I1019 15:06:32.378396 140597344753536 run_pretraining.py:173]   name = bert/encoder/layer_10/output/LayerNorm/gamma:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/query/kernel:0, shape = (768, 768)\n",
            "I1019 15:06:32.378654 140597344753536 run_pretraining.py:173]   name = bert/encoder/layer_11/attention/self/query/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/query/bias:0, shape = (768,)\n",
            "I1019 15:06:32.378889 140597344753536 run_pretraining.py:173]   name = bert/encoder/layer_11/attention/self/query/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/key/kernel:0, shape = (768, 768)\n",
            "I1019 15:06:32.379115 140597344753536 run_pretraining.py:173]   name = bert/encoder/layer_11/attention/self/key/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/key/bias:0, shape = (768,)\n",
            "I1019 15:06:32.379368 140597344753536 run_pretraining.py:173]   name = bert/encoder/layer_11/attention/self/key/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/value/kernel:0, shape = (768, 768)\n",
            "I1019 15:06:32.379645 140597344753536 run_pretraining.py:173]   name = bert/encoder/layer_11/attention/self/value/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/value/bias:0, shape = (768,)\n",
            "I1019 15:06:32.379918 140597344753536 run_pretraining.py:173]   name = bert/encoder/layer_11/attention/self/value/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/attention/output/dense/kernel:0, shape = (768, 768)\n",
            "I1019 15:06:32.380143 140597344753536 run_pretraining.py:173]   name = bert/encoder/layer_11/attention/output/dense/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/attention/output/dense/bias:0, shape = (768,)\n",
            "I1019 15:06:32.380373 140597344753536 run_pretraining.py:173]   name = bert/encoder/layer_11/attention/output/dense/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/attention/output/LayerNorm/beta:0, shape = (768,)\n",
            "I1019 15:06:32.380618 140597344753536 run_pretraining.py:173]   name = bert/encoder/layer_11/attention/output/LayerNorm/beta:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
            "I1019 15:06:32.380854 140597344753536 run_pretraining.py:173]   name = bert/encoder/layer_11/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/intermediate/dense/kernel:0, shape = (768, 3072)\n",
            "I1019 15:06:32.381093 140597344753536 run_pretraining.py:173]   name = bert/encoder/layer_11/intermediate/dense/kernel:0, shape = (768, 3072)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/intermediate/dense/bias:0, shape = (3072,)\n",
            "I1019 15:06:32.381384 140597344753536 run_pretraining.py:173]   name = bert/encoder/layer_11/intermediate/dense/bias:0, shape = (3072,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/output/dense/kernel:0, shape = (3072, 768)\n",
            "I1019 15:06:32.381711 140597344753536 run_pretraining.py:173]   name = bert/encoder/layer_11/output/dense/kernel:0, shape = (3072, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/output/dense/bias:0, shape = (768,)\n",
            "I1019 15:06:32.381935 140597344753536 run_pretraining.py:173]   name = bert/encoder/layer_11/output/dense/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/output/LayerNorm/beta:0, shape = (768,)\n",
            "I1019 15:06:32.382156 140597344753536 run_pretraining.py:173]   name = bert/encoder/layer_11/output/LayerNorm/beta:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/output/LayerNorm/gamma:0, shape = (768,)\n",
            "I1019 15:06:32.382463 140597344753536 run_pretraining.py:173]   name = bert/encoder/layer_11/output/LayerNorm/gamma:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/pooler/dense/kernel:0, shape = (768, 768)\n",
            "I1019 15:06:32.382723 140597344753536 run_pretraining.py:173]   name = bert/pooler/dense/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/pooler/dense/bias:0, shape = (768,)\n",
            "I1019 15:06:32.382965 140597344753536 run_pretraining.py:173]   name = bert/pooler/dense/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = cls/predictions/transform/dense/kernel:0, shape = (768, 768)\n",
            "I1019 15:06:32.383241 140597344753536 run_pretraining.py:173]   name = cls/predictions/transform/dense/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = cls/predictions/transform/dense/bias:0, shape = (768,)\n",
            "I1019 15:06:32.383534 140597344753536 run_pretraining.py:173]   name = cls/predictions/transform/dense/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = cls/predictions/transform/LayerNorm/beta:0, shape = (768,)\n",
            "I1019 15:06:32.383760 140597344753536 run_pretraining.py:173]   name = cls/predictions/transform/LayerNorm/beta:0, shape = (768,)\n",
            "INFO:tensorflow:  name = cls/predictions/transform/LayerNorm/gamma:0, shape = (768,)\n",
            "I1019 15:06:32.383983 140597344753536 run_pretraining.py:173]   name = cls/predictions/transform/LayerNorm/gamma:0, shape = (768,)\n",
            "INFO:tensorflow:  name = cls/predictions/output_bias:0, shape = (967,)\n",
            "I1019 15:06:32.384252 140597344753536 run_pretraining.py:173]   name = cls/predictions/output_bias:0, shape = (967,)\n",
            "INFO:tensorflow:  name = cls/seq_relationship/output_weights:0, shape = (2, 768)\n",
            "I1019 15:06:32.384552 140597344753536 run_pretraining.py:173]   name = cls/seq_relationship/output_weights:0, shape = (2, 768)\n",
            "INFO:tensorflow:  name = cls/seq_relationship/output_bias:0, shape = (2,)\n",
            "I1019 15:06:32.384789 140597344753536 run_pretraining.py:173]   name = cls/seq_relationship/output_bias:0, shape = (2,)\n",
            "WARNING:tensorflow:From /content/bert/optimization.py:27: The name tf.train.get_or_create_global_step is deprecated. Please use tf.compat.v1.train.get_or_create_global_step instead.\n",
            "\n",
            "W1019 15:06:32.385105 140597344753536 module_wrapper.py:139] From /content/bert/optimization.py:27: The name tf.train.get_or_create_global_step is deprecated. Please use tf.compat.v1.train.get_or_create_global_step instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/bert/optimization.py:32: The name tf.train.polynomial_decay is deprecated. Please use tf.compat.v1.train.polynomial_decay instead.\n",
            "\n",
            "W1019 15:06:32.386135 140597344753536 module_wrapper.py:139] From /content/bert/optimization.py:32: The name tf.train.polynomial_decay is deprecated. Please use tf.compat.v1.train.polynomial_decay instead.\n",
            "\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/math_grad.py:1375: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "W1019 15:06:32.621125 140597344753536 deprecation.py:323] From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/math_grad.py:1375: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I1019 15:06:39.672688 140597344753536 estimator.py:1150] Done calling model_fn.\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "I1019 15:06:39.674271 140597344753536 basic_session_run_hooks.py:541] Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "I1019 15:06:42.532142 140597344753536 monitored_session.py:240] Graph was finalized.\n",
            "2020-10-19 15:06:42.545248: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2200000000 Hz\n",
            "2020-10-19 15:06:42.545573: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x30ccbc0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2020-10-19 15:06:42.545609: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "2020-10-19 15:06:42.551185: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
            "2020-10-19 15:06:42.719901: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-10-19 15:06:42.721143: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x30cd640 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2020-10-19 15:06:42.721176: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla P100-PCIE-16GB, Compute Capability 6.0\n",
            "2020-10-19 15:06:42.722666: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-10-19 15:06:42.723724: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
            "name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n",
            "pciBusID: 0000:00:04.0\n",
            "2020-10-19 15:06:42.724141: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-10-19 15:06:42.987776: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2020-10-19 15:06:43.114800: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2020-10-19 15:06:43.140656: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2020-10-19 15:06:43.406787: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2020-10-19 15:06:43.443730: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2020-10-19 15:06:43.938259: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-10-19 15:06:43.938590: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-10-19 15:06:43.939915: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-10-19 15:06:43.941106: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
            "2020-10-19 15:06:43.944969: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-10-19 15:06:43.946921: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2020-10-19 15:06:43.946996: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n",
            "2020-10-19 15:06:43.947026: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n",
            "2020-10-19 15:06:43.948156: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-10-19 15:06:43.949156: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-10-19 15:06:43.950055: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2020-10-19 15:06:43.950154: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15216 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "I1019 15:06:55.399016 140597344753536 session_manager.py:500] Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "I1019 15:06:55.584095 140597344753536 session_manager.py:502] Done running local_init_op.\n",
            "INFO:tensorflow:Saving checkpoints for 0 into /content/my_pretrained_model/model.ckpt.\n",
            "I1019 15:07:01.987027 140597344753536 basic_session_run_hooks.py:606] Saving checkpoints for 0 into /content/my_pretrained_model/model.ckpt.\n",
            "2020-10-19 15:07:10.971592: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ydspZHM8nvQB"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}