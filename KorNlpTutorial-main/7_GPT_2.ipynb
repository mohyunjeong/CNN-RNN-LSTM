{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "7_GPT-2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python37364bitvenvvenvfefc9bbb02644ec2a36fa207a9f237c2",
      "display_name": "Python 3.7.3 64-bit ('venv': venv)"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cZqKCBMVygPM"
      },
      "source": [
        "# KorGPT2 Lyric Fine-Tuning Tutorial\n",
        "https://github.com/MrBananaHuman/KorGPT2Tutorial"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lFMMI-b1bWuX",
        "outputId": "e4c831f4-1026-46a4-cc88-004c2b7c1b4a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        }
      },
      "source": [
        "!git clone https://github.com/MrBananaHuman/KorGPT2Tutorial.git"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'KorGPT2Tutorial'...\n",
            "remote: Enumerating objects: 9, done.\u001b[K\n",
            "remote: Counting objects: 100% (9/9), done.\u001b[K\n",
            "remote: Compressing objects: 100% (9/9), done.\u001b[K\n",
            "remote: Total 344 (delta 2), reused 0 (delta 0), pack-reused 335\u001b[K\n",
            "Receiving objects: 100% (344/344), 1.55 MiB | 16.20 MiB/s, done.\n",
            "Resolving deltas: 100% (192/192), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NP5Y2GcYbaf-",
        "outputId": "e8ac8cd0-7214-4058-9ffa-975a7e92b59f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 582
        }
      },
      "source": [
        "!pip install -r /content/KorGPT2Tutorial/requirements.txt"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tqdm==4.46.0 in /usr/local/lib/python3.6/dist-packages (from -r /content/KorGPT2Tutorial/requirements.txt (line 1)) (4.46.0)\n",
            "Requirement already satisfied: numpy==1.18.5 in /usr/local/lib/python3.6/dist-packages (from -r /content/KorGPT2Tutorial/requirements.txt (line 2)) (1.18.5)\n",
            "Collecting ptvsd==4.3.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/c9/b9dff94aa7fafcdd761e4159c23322a807469bc59bb64f5d9eb298570984/ptvsd-4.3.2-cp36-cp36m-manylinux1_x86_64.whl (5.9MB)\n",
            "\u001b[K     |████████████████████████████████| 5.9MB 4.5MB/s \n",
            "\u001b[?25hCollecting tensorboardX==2.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/35/f1/5843425495765c8c2dd0784a851a93ef204d314fc87bcc2bbb9f662a3ad1/tensorboardX-2.0-py2.py3-none-any.whl (195kB)\n",
            "\u001b[K     |████████████████████████████████| 204kB 35.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: tokenizers==0.7.0 in /usr/local/lib/python3.6/dist-packages (from -r /content/KorGPT2Tutorial/requirements.txt (line 5)) (0.7.0)\n",
            "Requirement already satisfied: torch==1.5.0 in /usr/local/lib/python3.6/dist-packages (from -r /content/KorGPT2Tutorial/requirements.txt (line 6)) (1.5.0)\n",
            "Requirement already satisfied: transformers==2.11.0 in /usr/local/lib/python3.6/dist-packages (from -r /content/KorGPT2Tutorial/requirements.txt (line 7)) (2.11.0)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorboardX==2.0->-r /content/KorGPT2Tutorial/requirements.txt (line 4)) (3.12.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from tensorboardX==2.0->-r /content/KorGPT2Tutorial/requirements.txt (line 4)) (1.15.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch==1.5.0->-r /content/KorGPT2Tutorial/requirements.txt (line 6)) (0.16.0)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (from transformers==2.11.0->-r /content/KorGPT2Tutorial/requirements.txt (line 7)) (0.1.91)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers==2.11.0->-r /content/KorGPT2Tutorial/requirements.txt (line 7)) (0.0.43)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers==2.11.0->-r /content/KorGPT2Tutorial/requirements.txt (line 7)) (20.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers==2.11.0->-r /content/KorGPT2Tutorial/requirements.txt (line 7)) (2.23.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers==2.11.0->-r /content/KorGPT2Tutorial/requirements.txt (line 7)) (2019.12.20)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers==2.11.0->-r /content/KorGPT2Tutorial/requirements.txt (line 7)) (0.7)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers==2.11.0->-r /content/KorGPT2Tutorial/requirements.txt (line 7)) (3.0.12)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.8.0->tensorboardX==2.0->-r /content/KorGPT2Tutorial/requirements.txt (line 4)) (50.3.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==2.11.0->-r /content/KorGPT2Tutorial/requirements.txt (line 7)) (0.16.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==2.11.0->-r /content/KorGPT2Tutorial/requirements.txt (line 7)) (7.1.2)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers==2.11.0->-r /content/KorGPT2Tutorial/requirements.txt (line 7)) (2.4.7)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.11.0->-r /content/KorGPT2Tutorial/requirements.txt (line 7)) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.11.0->-r /content/KorGPT2Tutorial/requirements.txt (line 7)) (2020.6.20)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.11.0->-r /content/KorGPT2Tutorial/requirements.txt (line 7)) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.11.0->-r /content/KorGPT2Tutorial/requirements.txt (line 7)) (2.10)\n",
            "Installing collected packages: ptvsd, tensorboardX\n",
            "Successfully installed ptvsd-4.3.2 tensorboardX-2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5qpNEAhraMIb"
      },
      "source": [
        "## Download the pre-trained model\n",
        "* https://drive.google.com/drive/folders/124Uux07pym2YaCeQKQWNhzhLNeIlLm7r?usp=sharing "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "98ytte2a0DRT",
        "outputId": "e994c464-088a-481d-c94a-e80152073561",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "!mkdir -p KorGPT-2SampleModel\n",
        "!gdown -O ./KorGPT-2SampleModel/pytorch_model.bin --id 1kX_dB05dkLRgxJkqoHidrT2OFYHGYWPF"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1kX_dB05dkLRgxJkqoHidrT2OFYHGYWPF\n",
            "To: /content/KorGPT-2SampleModel/pytorch_model.bin\n",
            "516MB [00:03, 144MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "84WorptU8XxY",
        "outputId": "32501d3e-6856-4ffc-d776-52dfa7652114",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# tokenizer code\n",
        "!pygmentize /content/KorGPT2Tutorial/new_tokenizer.py"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mtokenizers.implementations\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m SentencePieceBPETokenizer\n",
            "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mtokenizers.processors\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m BertProcessing\n",
            "\n",
            "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mtransformers.tokenization_utils\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m PreTrainedTokenizer, PreTrainedTokenizerFast\n",
            "\n",
            "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mjson\u001b[39;49;00m\n",
            "\n",
            "\u001b[34mclass\u001b[39;49;00m \u001b[04m\u001b[32mMyTokenizer\u001b[39;49;00m():\n",
            "\n",
            "    \u001b[34mdef\u001b[39;49;00m \u001b[32m__init__\u001b[39;49;00m(\u001b[36mself\u001b[39;49;00m, vocab_file_path, merge_file_path):\n",
            "        \u001b[36mself\u001b[39;49;00m.tokenizer = SentencePieceBPETokenizer(vocab_file_path, merge_file_path)\n",
            "        \u001b[36mself\u001b[39;49;00m.unknown_token = \u001b[36mself\u001b[39;49;00m.tokenizer.token_to_id(\u001b[33m\"\u001b[39;49;00m\u001b[33m<unk>\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
            "        \u001b[36mself\u001b[39;49;00m._pad_token = \u001b[33m\"\u001b[39;49;00m\u001b[33m<pad>\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\n",
            "        \u001b[36mself\u001b[39;49;00m.pad_token_id = \u001b[36mself\u001b[39;49;00m.tokenizer.token_to_id(\u001b[33m\"\u001b[39;49;00m\u001b[33m<pad>\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
            "        \u001b[36mself\u001b[39;49;00m.max_len = \u001b[34m1024\u001b[39;49;00m\n",
            "        \u001b[36mself\u001b[39;49;00m.max_len_single_sentence = \u001b[34m1024\u001b[39;49;00m\n",
            "        \u001b[36mself\u001b[39;49;00m.init_kwargs = {}\n",
            "        \u001b[36mself\u001b[39;49;00m.added_tokens_encoder = {}\n",
            "        \u001b[36mself\u001b[39;49;00m.unique_added_tokens_encoder = \u001b[36mset\u001b[39;49;00m()\n",
            "        \u001b[36mself\u001b[39;49;00m.added_tokens_decoder = {}\n",
            "        \u001b[36mself\u001b[39;49;00m.unexpected_sep_token = [\u001b[33m'\u001b[39;49;00m\u001b[33m<pad>\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33m<unk>\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33m<eos>\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33m<sos>\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m]\n",
            "\n",
            "        \u001b[36mself\u001b[39;49;00m.encoder = \u001b[36mself\u001b[39;49;00m.tokenizer.get_vocab()\n",
            "        \u001b[36mself\u001b[39;49;00m.decoder = \u001b[36mdict\u001b[39;49;00m(\u001b[36mmap\u001b[39;49;00m(\u001b[36mreversed\u001b[39;49;00m, \u001b[36mself\u001b[39;49;00m.encoder.items()))\n",
            "\n",
            "    \n",
            "    \u001b[34mdef\u001b[39;49;00m \u001b[32mtokenize\u001b[39;49;00m(\u001b[36mself\u001b[39;49;00m, text):\n",
            "        \u001b[34mif\u001b[39;49;00m text \u001b[35min\u001b[39;49;00m \u001b[36mself\u001b[39;49;00m.unexpected_sep_token:\n",
            "            \u001b[34mreturn\u001b[39;49;00m text\n",
            "        \u001b[34mreturn\u001b[39;49;00m \u001b[36mself\u001b[39;49;00m.tokenizer.encode(text).tokens\n",
            "    \n",
            "    \u001b[34mdef\u001b[39;49;00m \u001b[32mconvert_tokens_to_ids\u001b[39;49;00m(\u001b[36mself\u001b[39;49;00m, tokens):\n",
            "        ids = []\n",
            "        \u001b[34mif\u001b[39;49;00m \u001b[36misinstance\u001b[39;49;00m(tokens, \u001b[36mstr\u001b[39;49;00m):\n",
            "            \u001b[34mif\u001b[39;49;00m tokens \u001b[35min\u001b[39;49;00m \u001b[36mself\u001b[39;49;00m.encoder:\n",
            "                \u001b[34mreturn\u001b[39;49;00m \u001b[36mself\u001b[39;49;00m.encoder[tokens]\n",
            "            \u001b[34melse\u001b[39;49;00m:\n",
            "                \u001b[34mreturn\u001b[39;49;00m \u001b[36mself\u001b[39;49;00m.unknown_token\n",
            "        \u001b[34mfor\u001b[39;49;00m token \u001b[35min\u001b[39;49;00m tokens:\n",
            "            \u001b[34mif\u001b[39;49;00m token \u001b[35min\u001b[39;49;00m \u001b[36mself\u001b[39;49;00m.encoder:\n",
            "                ids.append(\u001b[36mself\u001b[39;49;00m.encoder[token])\n",
            "            \u001b[34melse\u001b[39;49;00m:\n",
            "                ids.append(\u001b[36mself\u001b[39;49;00m.unknown_token)\n",
            "        \u001b[34mreturn\u001b[39;49;00m ids\n",
            "    \n",
            "    \u001b[34mdef\u001b[39;49;00m \u001b[32mconvert_ids_to_tokens\u001b[39;49;00m(\u001b[36mself\u001b[39;49;00m, ids):\n",
            "        sentence = \u001b[33m'\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\n",
            "        \u001b[34mfor\u001b[39;49;00m id_ \u001b[35min\u001b[39;49;00m ids:\n",
            "            sentence += \u001b[36mself\u001b[39;49;00m.decoder[id_]\n",
            "        sentence = sentence.replace(\u001b[33m'\u001b[39;49;00m\u001b[33m▁\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33m \u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\n",
            "        \u001b[34mreturn\u001b[39;49;00m sentence.strip()\n",
            "            \n",
            "    \n",
            "    \u001b[34mdef\u001b[39;49;00m \u001b[32mbuild_inputs_with_special_tokens\u001b[39;49;00m(\u001b[36mself\u001b[39;49;00m, ids):\n",
            "        \u001b[34mreturn\u001b[39;49;00m ids\n",
            "\n",
            "    \u001b[34mdef\u001b[39;49;00m \u001b[32mget_vocab_size\u001b[39;49;00m(\u001b[36mself\u001b[39;49;00m):\n",
            "        \u001b[34mreturn\u001b[39;49;00m \u001b[36mself\u001b[39;49;00m.tokenizer.get_vocab_size()\n",
            "\n",
            "    \u001b[34mdef\u001b[39;49;00m \u001b[32madd_special_tokens\u001b[39;49;00m(\u001b[36mself\u001b[39;49;00m, new_tokens):\n",
            "        \u001b[36mself\u001b[39;49;00m.tokenizer.add_special_tokens(new_tokens)\n",
            "        \u001b[36mself\u001b[39;49;00m.encoder = \u001b[36mself\u001b[39;49;00m.tokenizer.get_vocab()\n",
            "        \u001b[36mself\u001b[39;49;00m.decoder = \u001b[36mdict\u001b[39;49;00m(\u001b[36mmap\u001b[39;49;00m(\u001b[36mreversed\u001b[39;49;00m, \u001b[36mself\u001b[39;49;00m.encoder.items()))\n",
            "\n",
            "    \u001b[34mdef\u001b[39;49;00m \u001b[32madd_tokens\u001b[39;49;00m(\u001b[36mself\u001b[39;49;00m, new_tokens):\n",
            "        \u001b[36mself\u001b[39;49;00m.tokenizer.add_tokens(new_tokens)\n",
            "        \u001b[36mself\u001b[39;49;00m.encoder = \u001b[36mself\u001b[39;49;00m.tokenizer.get_vocab()\n",
            "        \u001b[36mself\u001b[39;49;00m.decoder = \u001b[36mdict\u001b[39;49;00m(\u001b[36mmap\u001b[39;49;00m(\u001b[36mreversed\u001b[39;49;00m, \u001b[36mself\u001b[39;49;00m.encoder.items()))\n",
            "\n",
            "\u001b[34mif\u001b[39;49;00m __name__ == \u001b[33m'\u001b[39;49;00m\u001b[33m__main__\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
            "    vocab_file_path = \u001b[33m'\u001b[39;49;00m\u001b[33mtokenizer/vocab.json\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\n",
            "    merge_file_path = \u001b[33m'\u001b[39;49;00m\u001b[33mtokenizer/merges.txt\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\n",
            "    tokenizer = MyTokenizer(vocab_file_path, merge_file_path)\n",
            "    sentence = \u001b[33m\"\u001b[39;49;00m\u001b[33m이순신은 조선 중기의 무신이다.\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\n",
            "    tokens = tokenizer.tokenize(sentence)\n",
            "    \u001b[34mprint\u001b[39;49;00m(tokens)\n",
            "    ids = tokenizer.convert_tokens_to_ids(tokens)\n",
            "    \u001b[34mprint\u001b[39;49;00m(ids)\n",
            "    ids2 = tokenizer.build_inputs_with_special_tokens(ids)\n",
            "    \u001b[34mprint\u001b[39;49;00m(ids2)\n",
            "    \u001b[34mprint\u001b[39;49;00m(tokenizer.convert_ids_to_tokens(ids))\n",
            "    \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aGoUa5BfaMIh"
      },
      "source": [
        "## Loading the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4MHF8tpxczkj",
        "outputId": "899e7343-2482-417f-f736-84cf88bd1c77",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "import sys\n",
        "print(sys.path)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['', '/env/python', '/usr/lib/python36.zip', '/usr/lib/python3.6', '/usr/lib/python3.6/lib-dynload', '/usr/local/lib/python3.6/dist-packages', '/usr/lib/python3/dist-packages', '/usr/local/lib/python3.6/dist-packages/IPython/extensions', '/root/.ipython']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wJtKqUod96-l",
        "outputId": "456e930f-6000-4197-d9da-6b59da831674",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from transformers import GPT2LMHeadModel, GPT2Config, AdamW\n",
        "from KorGPT2Tutorial import new_tokenizer\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "vocab_file_path = '/content/KorGPT2Tutorial/tokenizer/vocab.json'\n",
        "merge_file_path = '/content/KorGPT2Tutorial/tokenizer/merges.txt'\n",
        "model_dir = './KorGPT-2SampleModel/pytorch_model.bin'\n",
        "\n",
        "tokenizer = new_tokenizer.MyTokenizer(vocab_file_path, merge_file_path)\n",
        "config = GPT2Config(vocab_size=52000)\n",
        "model = GPT2LMHeadModel(config)\n",
        "  \n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model.load_state_dict(torch.load(model_dir, map_location=device), strict=False)\n",
        "model.to(device).eval()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GPT2LMHeadModel(\n",
              "  (transformer): GPT2Model(\n",
              "    (wte): Embedding(52000, 768)\n",
              "    (wpe): Embedding(1024, 768)\n",
              "    (drop): Dropout(p=0.1, inplace=False)\n",
              "    (h): ModuleList(\n",
              "      (0): Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (1): Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (2): Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (3): Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (4): Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (5): Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (6): Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (7): Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (8): Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (9): Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (10): Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (11): Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "  )\n",
              "  (lm_head): Linear(in_features=768, out_features=52000, bias=False)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UMZfxyQVaMIm"
      },
      "source": [
        "ATTR_TO_SPECIAL_TOKEN = ['<song>', '</song>']\n",
        "\n",
        "def add_special_tokens_(model, tokenizer):\n",
        "    orig_num_tokens = tokenizer.get_vocab_size()\n",
        "    tokenizer.add_special_tokens(ATTR_TO_SPECIAL_TOKEN)\n",
        "    num_added_tokens = len(ATTR_TO_SPECIAL_TOKEN)\n",
        "    model.resize_token_embeddings(new_num_tokens=orig_num_tokens + num_added_tokens + 1)\n",
        "\n",
        "add_special_tokens_(model, tokenizer)\n",
        "b_song = tokenizer.convert_tokens_to_ids('<song>')\n",
        "e_song = tokenizer.convert_tokens_to_ids('</song>')"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SrHQ0vmaaMIp"
      },
      "source": [
        "## Line by line dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gizNKaSWdQu9",
        "outputId": "4f0bfd7d-5105-4f38-8f56-9dc1748b350e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "!curl -c ./cookie -s -L \"https://drive.google.com/uc?export=download&id=1KNBYxol8ZEqLgdJKmil1DN0gRO7ofcit\" > /dev/null\n",
        "!curl -Lb ./cookie \"https://drive.google.com/uc?export=download&confirm=`awk '/download/ {print $NF}' ./cookie`&id=1KNBYxol8ZEqLgdJKmil1DN0gRO7ofcit\" -o preprocessed_data"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100   408    0   408    0     0    569      0 --:--:-- --:--:-- --:--:--   568\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "100 14.9M    0 14.9M    0     0  14.2M      0 --:--:--  0:00:01 --:--:-- 14.2M\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jEDeF64x06sp"
      },
      "source": [
        "class LyricDataSet(Dataset):\n",
        "    def __init__(self, file_path):\n",
        "        self.data = []\n",
        "        self.file_path = file_path\n",
        "        \n",
        "    def split_songs(self, lines):\n",
        "        songs = []\n",
        "        single_song = []\n",
        "        for line in lines:\n",
        "            line = line.strip()\n",
        "            if line == '':\n",
        "                if len(single_song) > 5:\n",
        "                    songs.append(single_song)\n",
        "                single_song = []\n",
        "            else:\n",
        "                single_song.append(line)\n",
        "        return songs\n",
        "    \n",
        "    def load_data(self):\n",
        "        lyric_file = open(self.file_path, 'r', encoding='utf-8')\n",
        "        lyric_lines = lyric_file.readlines()\n",
        "        lyric_file.close()\n",
        "        \n",
        "        song_list = self.split_songs(lyric_lines)\n",
        "        for song in song_list:\n",
        "            song_data = ['<song>']\n",
        "            for line in song:\n",
        "                tokenized_line = ['<s>'] + tokenizer.tokenize(line) + ['</s>']\n",
        "                if len(song_data) + len(tokenized_line) < 1024:\n",
        "                    song_data += tokenized_line\n",
        "                else:\n",
        "                    break\n",
        "            song_data += ['</song>']\n",
        "            padded_song_data = song_data + ['<pad>'] * (1024 - len(song_data))\n",
        "            self.data.append(torch.tensor(tokenizer.convert_tokens_to_ids(padded_song_data)).unsqueeze(0))\n",
        "                \n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        item = self.data[index]\n",
        "        return item\n",
        "\n",
        "\n",
        "    \n",
        "lyric_file_path = '/content/preprocessed_data'\n",
        "lyric_data = LyricDataSet(lyric_file_path)\n",
        "lyric_data.load_data()\n",
        "lyric_data_loader = DataLoader(lyric_data, batch_size=4, shuffle=True)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fwWpWnK-aMIr"
      },
      "source": [
        "## Find tuning/training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lu-HL7WDaMIs"
      },
      "source": [
        "optimizer = AdamW(model.parameters(), lr=1e-4, correct_bias=True)\n",
        "\n",
        "epochs = 5\n",
        "count = 0\n",
        "\n",
        "avg_loss = (0.0, 0.0)\n",
        "for epoch in range(epochs):\n",
        "\tfor data in lyric_data_loader:\n",
        "\t\toptimizer.zero_grad()\n",
        "\t\tdata = data.transpose(1,0)\n",
        "\t\tdata = data.to(device)\n",
        "\t\tmodel = model.to(device)\n",
        "\n",
        "\t\toutputs = model(data, labels=data)\n",
        "\t\tloss, logits = outputs[:2]\n",
        "\t\tloss = loss.to(device)\n",
        "\t\tloss.backward()\n",
        "\t\tavg_loss = (avg_loss[0] * 0.99 + loss, avg_loss[1] * 0.99 + 1.0)\n",
        "\t\toptimizer.step()\n",
        "\t\tcount+=1\n",
        "\n",
        "\tprint('epoch no.{0} train no.{1}  loss = {2:.5f} avg_loss = {3:.5f}' . format(epoch, count, loss, avg_loss[0] / avg_loss[1]))\n",
        "\t\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jLDamFuxDHey"
      },
      "source": [
        "# Save the mode \n",
        "from os import path\n",
        "\n",
        "torch.save(model.state_dict(), \n",
        "    path.join(path.dirname(model_dir), 'my_lyric_model.bin'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GpyOorlVBw1n",
        "outputId": "ea57d317-4607-4ae9-eca7-d1ed82ff0a23",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "bos = tokenizer.convert_tokens_to_ids('<s>')\n",
        "eos = tokenizer.convert_tokens_to_ids('</s>')\n",
        "pad = tokenizer.convert_tokens_to_ids('<pad>')\n",
        "unk = tokenizer.convert_tokens_to_ids('<unk>')\n",
        "\n",
        "def add_special_tokens_(model, tokenizer):\n",
        "    orig_num_tokens = tokenizer.get_vocab_size()\n",
        "    tokenizer.add_special_tokens(ATTR_TO_SPECIAL_TOKEN)\n",
        "    num_added_tokens = len(ATTR_TO_SPECIAL_TOKEN)\n",
        "    model.resize_token_embeddings(new_num_tokens=orig_num_tokens + num_added_tokens + 1)\n",
        "\n",
        "add_special_tokens_(model, tokenizer)\n",
        "b_song = tokenizer.convert_tokens_to_ids('<song>')\n",
        "e_song = tokenizer.convert_tokens_to_ids('</song>')\n",
        "\n",
        "def encoding(text):\n",
        "    tokens = ['<song>', '<s>'] + tokenizer.tokenize(text)\n",
        "    return torch.tensor(tokenizer.convert_tokens_to_ids(tokens)).unsqueeze(0)\n",
        "\n",
        "def decoding(ids):\n",
        "    return tokenizer.convert_ids_to_tokens(ids[0])\n",
        "\n",
        "input_ids = encoding('하늘을 날아')\n",
        "\n",
        "sample_outputs = model.generate(\n",
        "    input_ids,\n",
        "    do_sample=True, \n",
        "    max_length=1024, \n",
        "    top_k=50, \n",
        "    top_p=0.95, \n",
        "    eos_token_id=e_song,\n",
        "    early_stopping=True,\n",
        "    bad_words_ids=[[unk]]\n",
        ")\n",
        "print(decoding(sample_outputs.tolist()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to 52001 (first `eos_token_id`) to generate sequence\n",
            "<song><s> 하늘을 날아야 한다고 말한다.</s><s> 그리고 얼마 후 어느 날, 갑자기 </s><s> </s><s> 시몽, 마블의 첫 등장에 이어서 등장한 카드.</s><s> </s><s> 첫 등장은 4화부터 등장.</s><s> 시몽을 위해 시몽에게 도움을 요청할 때 시몽의 적인 효과를 사용해 시몽을 소환하는 것이 주된 포인트였다.</s><s> 시몽의 등장은  시몽의 등장이 아니라며 시몽의 등장을 위해 시몽에게 연락을 받고 시몽의 등장에 들어간다.</s><s> 시몽의 등장은 4화에서 시몽이 재등장한다.</s><s> 시몽은 재등장.</s><s> 시몽의 등장은 6화에서 시몽이 재등장한다.</s><s> 시몽이 재등장하면서 시몽을 재등장시킨다.</s><s> 시몽이 재등장하면서 시몽의 등장은 4화에서 시몽의 등장은 5화에서 시몽이 재등장한다.</s><s> 시몽의 등장은 6화에서 시몽에게 첫 등장이 확정되었다.</s><s> 시몽은 재등장했으나 시몽의 등장이 3화에서 시몽에게 첫 등장을 하게 되자 시몽의 등장이 확정되고 시몽이 재등장한다.</s><s> 시몽이 재등장하자 시몽은 재등장하지만 시몽에게 등장을 하지 않는다.</s><s> 시몽이 재등장한다.</s><s> 시몽은 재등장하지만 시몽이 재등장해 시몽이 재등장한다.</s><s> 시몽은 재등장한다.</s><s> 시몽에게 등장이지만 시몽의 등장은 5화에서 시몽을 재등장한다.</s><s> 시몽에게 등장은 12화에서 시몽에게 재등장을 하면서 시몽의 등장은 9화에서 시몽에게 등장은 12화, 시몽이 재등장한다.</s><s> 시몽이 재등장해 시몽이 재등장해 시몽을 재등장.</s><s> 시몽을 재등장하고 시몽을 재등장한다.</s><s> 시몽을 재등장해 시몽의 등장은 6화에서 시몽에게 처음으로 등장은 23화에서 시몽이 재등장해 시몽이 재등장해 시몽의 등장은 7화에서 시몽이 재등장해 시몽이 재등장해 시몽을 재등장.</s><s> 시몽이 재등장하며 시몽은 재등장하나 시몽이 재등장해 시몽을 재등장.</s><s> 시몽을 재등장.</s><s> 시몽이 재등장해 시몽을 재등장.</s><s> 시몽의 등장은 6화에서 시몽이 재등장해 시몽을 재등장.</s><s> 시몽은 재등장하지만 시몽을 재등장해 시몽을 재등장.</s><s> 시몽을 재등장해 시몽의 등장은 5화에서 시몽을 재등장.</s><s> 시몽은 재등장하지만 시몽이 재등장해 시몽이 재등장해 시몽을 재등장.</s><s> 시몽의 등장은 6화에서 시몽을 재등장.</s><s> 시몽에게 등장은 29화에서 시몽에게 재등장.</s><s> 시몽이 재등장해 시몽에게 등장은 7화에서 시몽의 등장이 확정되었다.</s><s> 시몽의 등장은 8화에서 시몽이 재등장하며 시몽의 등장은 8화에서 시몽이 재등장했다.</s><s> 시몽이 재등장해 시몽의 등장은 5화에서 시몽에게 재등장해 시몽의 등장은 6화에서 시몽에게 등장의 등장은 5화에서 시몽을 재등장.</s><s> 시몽의 등장은 9화에서 시몽이 재등장해 시몽이 재등장해 시몽이 재등장.</s><s> 시몽은 재등장해 시몽이 재등장해 시몽의 등장이 확정되었다.</s><s> 시몽이 재등장해 시몽을 재등장.</s><s> 시몽의 등장은 8화에서 시몽이 재등장해 시몽의 등장은 14화에서 시몽의 등장은 9화에서 시몽이 재등장.</s><s> 시몽에게 등장은 11화에서 시몽을 재등장.</s><s> 시몽의 등장은 9화에서 시몽이 재등장해 시몽의 등장은 11화에서 시몽이 재등장.</s><s> 시몽에게 등장은 10화에서 시몽이 재등장해 시몽의 등장은 11화에서 시몽에게 등장은 9화에서 시몽의 등장은 9화에서 시몽에게 재등장.</s><s> 시몽은 재등장.</s><s> 시몽을 재등장.</s><s> 시몽에게 등장은 11화에서 시몽이 재등장해 시몽의 등장이 확정되었다.</s><s> 시몽은 재등장이지만 시몽의 등장은 4화에서 시몽의 등장은 9화에서 시몽에게 재등장해 시몽의 등장은 7화에서 시몽의 등장은 9화에서 시몽의 등장은 9화의 등장은 11화에서 시몽에게 재등장해 시몽이 재등장해 시몽을 재등장.</s><s> 시몽과의 등장은 23화에서 시몽의 등장은 11화에서 시몽에게 등장을 해 시몽을 재등장해 시몽이 재등장해 시몽의\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cf4QGV_-ByFY"
      },
      "source": [
        "## Decoding using the saved model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kce9wLqq-Yni",
        "outputId": "dff61ab7-5f56-4059-df89-b5cfa48f40b7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        }
      },
      "source": [
        "!mkdir -p KorGPT-2SampleModel\n",
        "!gdown -O ./KorGPT-2SampleModel/lyric_model.bin --id 1nopu647K2KwnMAc97CNL2owPKA4GsF22"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1nopu647K2KwnMAc97CNL2owPKA4GsF22\n",
            "To: /Users/hunkim/work/KorGPT2Tutorial/KorGPT-2SampleModel/lyric_model.bin\n",
            "516MB [00:16, 31.9MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XLqQmOTIEZ03",
        "outputId": "7a568465-49ec-4637-dd09-7acb3e079d26",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from transformers import GPT2LMHeadModel, GPT2Config\n",
        "import torch\n",
        "\n",
        "ATTR_TO_SPECIAL_TOKEN = ['<song>', '</song>']\n",
        "\n",
        "vocab_file_path = './tokenizer/vocab.json'\n",
        "merge_file_path = './tokenizer/merges.txt'\n",
        "model_dir = './KorGPT-2SampleModel/lyric_model.bin'\n",
        "\n",
        "tokenizer = MyTokenizer(vocab_file_path, merge_file_path)\n",
        "bos = tokenizer.convert_tokens_to_ids('<s>')\n",
        "eos = tokenizer.convert_tokens_to_ids('</s>')\n",
        "pad = tokenizer.convert_tokens_to_ids('<pad>')\n",
        "unk = tokenizer.convert_tokens_to_ids('<unk>')\n",
        "\n",
        "config = GPT2Config(vocab_size=52003, resid_pdrop=0, embd_pdrop=0, attn_pdrop=0, summary_first_dropout=0)\n",
        "model = GPT2LMHeadModel(config)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.load_state_dict(torch.load(model_dir, map_location=device), strict=False)\n",
        "model.to(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GPT2LMHeadModel(\n",
              "  (transformer): GPT2Model(\n",
              "    (wte): Embedding(52003, 768)\n",
              "    (wpe): Embedding(1024, 768)\n",
              "    (drop): Dropout(p=0, inplace=False)\n",
              "    (h): ModuleList(\n",
              "      (0): Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (dropout): Dropout(p=0, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (1): Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (dropout): Dropout(p=0, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (2): Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (dropout): Dropout(p=0, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (3): Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (dropout): Dropout(p=0, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (4): Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (dropout): Dropout(p=0, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (5): Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (dropout): Dropout(p=0, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (6): Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (dropout): Dropout(p=0, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (7): Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (dropout): Dropout(p=0, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (8): Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (dropout): Dropout(p=0, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (9): Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (dropout): Dropout(p=0, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (10): Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (dropout): Dropout(p=0, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (11): Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (dropout): Dropout(p=0, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "  )\n",
              "  (lm_head): Linear(in_features=768, out_features=52003, bias=False)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hyzhBjTt-ToD",
        "outputId": "5a0a84ce-ab9c-4f9f-cdaf-969d5135694c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "\n",
        "\n",
        "def add_special_tokens_(model, tokenizer):\n",
        "    orig_num_tokens = tokenizer.get_vocab_size()\n",
        "    tokenizer.add_special_tokens(ATTR_TO_SPECIAL_TOKEN)\n",
        "    num_added_tokens = len(ATTR_TO_SPECIAL_TOKEN)\n",
        "    model.resize_token_embeddings(new_num_tokens=orig_num_tokens + num_added_tokens + 1)\n",
        "\n",
        "add_special_tokens_(model, tokenizer)\n",
        "b_song = tokenizer.convert_tokens_to_ids('<song>')\n",
        "e_song = tokenizer.convert_tokens_to_ids('</song>')\n",
        "\n",
        "def encoding(text):\n",
        "    tokens = ['<song>', '<s>'] + tokenizer.tokenize(text)\n",
        "    return torch.tensor(tokenizer.convert_tokens_to_ids(tokens)).unsqueeze(0)\n",
        "\n",
        "def decoding(ids):\n",
        "    return tokenizer.convert_ids_to_tokens(ids[0])\n",
        "\n",
        "input_ids = encoding('우리는 오늘')\n",
        "\n",
        "sample_outputs = model.generate(\n",
        "    input_ids,\n",
        "    do_sample=True, \n",
        "    max_length=1024, \n",
        "    top_k=50, \n",
        "    top_p=0.95, \n",
        "    eos_token_id=e_song,\n",
        "    early_stopping=True,\n",
        "    bad_words_ids=[[unk]]\n",
        ")\n",
        "print(decoding(sample_outputs.tolist()))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to 52001 (first `eos_token_id`) to generate sequence\n",
            "<song><s> 우리는 오늘 밤도 오늘 밤</s><s> 함께 걷던 이 곳</s><s> 우리 둘 사이엔 아직 많은 날들이</s><s> 우리 둘의 추억을 함께했던 추억은 사라져 버렸어</s><s> 우리의 사랑은 우리의 우정</s><s> 우리 둘이 함께했던 기억엔</s><s> 우리의 추억이 남아 있어요</s><s> 우리의 추억을 함께했던 시간엔</s><s> 우리의 추억이 남아 있어요</s><s> 우리 둘은 함께한 기억이 남아 있어요</s><s> 우리의 추억을 함께했던 시간엔</s><s> 우리의 추억이 남아 있어요</s><s> 우리의 추억을 함께했던 시간엔</s><s> 우리의 추억이 남아 있어요</s><s> 우리의 추억을 함께했던 시간엔</s><s> 우리의 추억이 남아 있어요</s></song>\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CLDBrtocaMI6"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}