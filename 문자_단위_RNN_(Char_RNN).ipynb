{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## ✅ 문자 단위 RNN (Char RNN)\n",
        "- 입출력의 단위가 단어 레벨이 아니라 문자 레벨"
      ],
      "metadata": {
        "id": "nh7nG6JA5p4Z"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gF3ngpIX5l4J"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ✅ 1. 훈련 데이터 전처리\n",
        "- 입력 데이터와 레이블에 대해서 문자 집합을 만들겠습니다. -> 중복은 제외해야 함!"
      ],
      "metadata": {
        "id": "FMYn0Zdm6CHK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_str = 'apple'\n",
        "output_str = 'pple!'\n",
        "\n",
        "char_vocab = sorted(list(set((input_str + output_str))))\n",
        "\n",
        "vocab_size = len(char_vocab)\n",
        "print('문자 집합 크기 : {}'.format(vocab_size))"
      ],
      "metadata": {
        "id": "wzpIgYJX6JHh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 📌 입력은 one-hot 벡터를 사용할 것이기 때문에 **입력의 크기는 문자 집합의 크기**가 되어야 함"
      ],
      "metadata": {
        "id": "uQu_BVi86JuL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_size = vocab_size\n",
        "hidden_size = 5\n",
        "output_size = 5\n",
        "lr = 0.1"
      ],
      "metadata": {
        "id": "B2rGarlG6Jr9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 📌 문자 집합에 레이블 부여"
      ],
      "metadata": {
        "id": "9D8lZxNa7NPD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "char_to_index = dict((c, i) for i, c in enumerate(char_vocab))\n",
        "\n",
        "print(char_to_index)"
      ],
      "metadata": {
        "id": "H4lt2uS86Jpf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "index_to_char = dict()\n",
        "\n",
        "for k, v in char_to_index.items():\n",
        "    index_to_char[v] = k\n",
        "\n",
        "print(index_to_char)"
      ],
      "metadata": {
        "id": "wYen4UyA6JnJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 📌 입력 데이터와 레이블 데이터를 구성하는 문자들을 정수로 맵핑하겠습니다."
      ],
      "metadata": {
        "id": "hn4Snj2U8Tqe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_data = [char_to_index[c] for c in input_str]\n",
        "y_data = [char_to_index[c] for c in output_str]\n",
        "\n",
        "print(x_data)\n",
        "print(y_data)"
      ],
      "metadata": {
        "id": "XH4bVD7J6JkO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 📌 NLP에서는 3차원 텐서가 기본이기 때문에, 배치 차원을 추가해주겠습니다."
      ],
      "metadata": {
        "id": "cdwT-4Oa9gar"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 배치 차원 추가\n",
        "\n",
        "x_data_ = [x_data]\n",
        "y_data_ = [y_data]\n",
        "\n",
        "print(x_data_)\n",
        "print(y_data_)"
      ],
      "metadata": {
        "id": "4SNZ4Ua46JgH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Pytorch에서의 텐서 연산인 unsqueeze(0)도 활용 가능\n",
        "\n",
        "x_data2 = torch.tensor(x_data).unsqueeze(0)\n",
        "y_data2 = torch.tensor(y_data).unsqueeze(0)\n",
        "\n",
        "print(x_data2.shape)\n",
        "print(y_data2.shape)"
      ],
      "metadata": {
        "id": "Z0LkHR-o6Jdq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 📌 입력 시퀀스의 각 문자들을 one-hot 벡터로 변환!"
      ],
      "metadata": {
        "id": "-CtYa-hw-KWG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_one_hot = [np.eye(vocab_size)[x] for x in x_data_]\n",
        "\n",
        "print(x_one_hot)"
      ],
      "metadata": {
        "id": "Wjsj93xi6Jav"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 📌 입력과 레이블 데이터를 텐서로 캐스팅 해주겠습니다"
      ],
      "metadata": {
        "id": "tPu-4hOY-x-D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = torch.FloatTensor(x_one_hot)\n",
        "Y = torch.LongTensor(y_data_)"
      ],
      "metadata": {
        "id": "V-Yk9XB9-HRd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 텐서의 shape 확인\n",
        "\n",
        "print('학습 데이터의 크기 : {}'.format(X.shape))\n",
        "print('레이블 데이터의 크기 : {}'.format(Y.shape))"
      ],
      "metadata": {
        "id": "jwFM11SO-HO3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ✅ 모델 구현하기"
      ],
      "metadata": {
        "id": "xFk1t82h_fP5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Net(nn.Module):\n",
        "\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "\n",
        "        super(Net, self).__init__()\n",
        "\n",
        "        self.rnn = nn.RNN(input_size, hidden_size, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, output_size, bias=True) # 출력층\n",
        "\n",
        "    def forward(self, x): # 구현한 RNN 셀과 FC 층을 연결하는 역할\n",
        "\n",
        "        x, _ = self.rnn(x)\n",
        "        x = self.fc(x)\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "4QMWBqyg-HL7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "net = Net(input_size, hidden_size, output_size)"
      ],
      "metadata": {
        "id": "om0ywPEq-HHu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "outputs = net(X)\n",
        "\n",
        "print(outputs.shape)"
      ],
      "metadata": {
        "id": "3EVY3MLQ-HFY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 📌 (1, 5, 5)의 크기를 가지는 output tensor를 나중에 정확도 측정을 위해 2차원 텐서로 바꾸는 과정이 필요함"
      ],
      "metadata": {
        "id": "J9htGQbOESIx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(outputs.view(-1, output_size).shape)"
      ],
      "metadata": {
        "id": "Tc5I_viB-HCV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(Y.shape)\n",
        "print(Y.view(-1).shape)"
      ],
      "metadata": {
        "id": "1T7Y2PpxAx3W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 📌 Optimzer와 loss function(criterion)을 정의해 봅시다"
      ],
      "metadata": {
        "id": "jUiWeMdQFEUG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(net.parameters(), lr)"
      ],
      "metadata": {
        "id": "06fWtjxoAx0M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training code\n",
        "\n",
        "epoch = 100\n",
        "\n",
        "for i in range(epoch):\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    outputs = net(X)\n",
        "\n",
        "    loss = criterion(outputs.view(-1, output_size), Y.view(-1)) # view() -> Batch dimension 제거를 위해\n",
        "    loss.backward() # 그래디언트 계산\n",
        "\n",
        "    optimizer.step()\n",
        "\n",
        "    # 프로그래스 바\n",
        "    result = outputs.data.numpy().argmax(axis=2) # output(5개의 값)에 대해서 가장 높은 값의 인덱스 선택!, 숫자 형태\n",
        "    result_str = ''.join([index_to_char[c] for c in np.squeeze(result)]) # helper function을 호출하여 char를 str 형태로 변환\n",
        "    print(i, \"loss : \", loss.item(), \"prediction : \", result, \"label : \", y_data, \"output_str : \", result_str)"
      ],
      "metadata": {
        "id": "MF8TKBBxAxuW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_str = 'ability'\n",
        "output_str = 'ity!!!!'\n",
        "\n",
        "char_vocab = sorted(list(set((input_str + output_str))))\n",
        "\n",
        "vocab_size = len(char_vocab)\n",
        "\n",
        "input_size = vocab_size\n",
        "hidden_size = 7\n",
        "output_size = 7\n",
        "lr = 0.1\n",
        "\n",
        "char_to_index = dict((c, i) for i, c in enumerate(char_vocab))\n",
        "\n",
        "index_to_char = dict()\n",
        "\n",
        "for k, v in char_to_index.items():\n",
        "    index_to_char[v] = k\n",
        "\n",
        "print(index_to_char)\n",
        "\n",
        "x_data = [char_to_index[c] for c in input_str]\n",
        "y_data = [char_to_index[c] for c in output_str]\n",
        "\n",
        "x_data_ = [x_data]\n",
        "y_data_ = [y_data]\n",
        "\n",
        "x_one_hot = [np.eye(vocab_size)[x] for x in x_data_]\n",
        "\n",
        "X = torch.FloatTensor(x_one_hot)\n",
        "Y = torch.LongTensor(y_data_)\n",
        "\n",
        "net = Net(input_size, hidden_size, output_size)\n",
        "\n",
        "outputs = net(X)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(net.parameters(), lr)\n",
        "\n",
        "epoch = 100\n",
        "\n",
        "for i in range(epoch):\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    outputs = net(X)\n",
        "\n",
        "    loss = criterion(outputs.view(-1, output_size), Y.view(-1))\n",
        "    loss.backward()\n",
        "\n",
        "    optimizer.step()\n",
        "\n",
        "    result = outputs.data.numpy().argmax(axis=2)\n",
        "    result_str = ''.join([index_to_char[c] for c in np.squeeze(result)])\n",
        "    print(i, \"loss : \", loss.item(), \"prediction : \", result, \"label : \", y_data, \"output_str : \", result_str)"
      ],
      "metadata": {
        "id": "FqUEGskuAxrZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 📍 문자 단위 RNN - with Sentence data"
      ],
      "metadata": {
        "id": "xWqhuAknK27D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim"
      ],
      "metadata": {
        "id": "csAUTEEPAxmt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ✅ 1. 훈련 데이터 전처리하기"
      ],
      "metadata": {
        "id": "kmMpAY0OLCh5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = (\"if you want to build a ship, don't drum up people together to \"\n",
        "            \"collect wood and don't assign them tasks and work, but rather \"\n",
        "            \"teach them to long for the endless immensity of the sea.\")"
      ],
      "metadata": {
        "id": "3Jfh1rPjAxiu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(sentence))"
      ],
      "metadata": {
        "id": "A4qQyjeXLmMn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "char_set = sorted(list(set(sentence))) # 문자 집합 생성\n",
        "char_dic = {c: i for i, c in enumerate(char_set)} # 각 문자에 정수 인코딩\n",
        "\n",
        "print(char_dic) # ❗❗ 문자에서는 공백도 하나의 원소로 대응 ❗❗"
      ],
      "metadata": {
        "id": "lpM3oFV3LmKq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 📌 각 문자에 single-digit 레이블을 부여하였으며, 25의 크기를 가지는 문자 집합 완성"
      ],
      "metadata": {
        "id": "gzBcAIelMIN2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('문자 집합의 크기 : {}'.format(len(char_dic)))"
      ],
      "metadata": {
        "id": "OUyf_Wd8LmIL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 📌 입력은 one-hot 벡터로 사용할 것이기 때문에 변환 과정 필요"
      ],
      "metadata": {
        "id": "UdM_MO_dMWjP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 문장 데이터이기 때문에 단위별로 끊어서 처리\n",
        "# sentence_length라는 변수를 활용해보자\n",
        "\n",
        "hidden_size = len(char_dic)\n",
        "sentence_length = 10 # 문장을 문자 10개 단위로 끊어서 전처리\n",
        "lr = 0.1"
      ],
      "metadata": {
        "id": "YHZl0yDhLmGF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 구성\n",
        "\n",
        "x_data = list()\n",
        "y_data = list()\n",
        "\n",
        "for i in range(0, len(sentence) - sentence_length):\n",
        "    x_str = sentence[i: i + sentence_length]\n",
        "    y_str = sentence[i + 1: i + sentence_length + 1]\n",
        "    print(i, x_str, '->', y_str)\n",
        "\n",
        "    x_data.append([char_dic[c] for c in x_str]) # 입력 데이터를 single-digit화\n",
        "    y_data.append([char_dic[c] for c in y_str])"
      ],
      "metadata": {
        "id": "KvSX1q0GLmDs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 📌 현재까지 총 170개로 구성된 데이터 셋(x, y 페어)를 생성하였음. 각 페어의 입력 데이터는 고유 정수로 인코딩이 된 상태"
      ],
      "metadata": {
        "id": "gaN9i2ucOL7Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_data[0])\n",
        "print(y_data[0])"
      ],
      "metadata": {
        "id": "9aDvnDLPLmBl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_one_hot = [np.eye(len(char_dic))[x] for x in x_data] # one-hot 벡터 새애성\n",
        "\n",
        "X = torch.FloatTensor(x_one_hot)\n",
        "Y = torch.LongTensor(y_data)"
      ],
      "metadata": {
        "id": "4akiJydULl_X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('학습 데이터의 크기 : {}'.format(X.shape))\n",
        "print('레이블 데이터의 크기 : {}'.format(Y.shape))"
      ],
      "metadata": {
        "id": "J2GZipT7AxeK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(Y[0])"
      ],
      "metadata": {
        "id": "_Ry0w4hTPZad"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ✅ 모델 구현하기"
      ],
      "metadata": {
        "id": "-0hkUcnZPiWV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Net(torch.nn.Module):\n",
        "\n",
        "    def __init__(self, input_dim, hidden_dim, layers):\n",
        "\n",
        "        super(Net, self).__init__()\n",
        "\n",
        "        self.rnn = torch.nn.RNN(input_dim, hidden_dim, num_layers=layers, batch_first=True)\n",
        "        self.fc = torch.nn.Linear(hidden_dim, hidden_dim, bias=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x, _ = self.rnn(x)\n",
        "        x = self.fc(x)\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "U2VvygADPZW0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dic_size = len(char_dic)\n",
        "\n",
        "net = Net(dic_size, hidden_size, 2) # hidden layer가 2층 짜리인 DRNN"
      ],
      "metadata": {
        "id": "Z9D5EM4ePZRk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 손실 함수\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# 옵티마이저\n",
        "\n",
        "optimizer = optim.Adam(net.parameters(), lr)"
      ],
      "metadata": {
        "id": "oJFcFhfUPZPB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ✅ 학습 진행"
      ],
      "metadata": {
        "id": "s65AFPYeTecV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epoch = 100\n",
        "\n",
        "for i in range(epoch):\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    outputs = net(X) # (170, 10, 25) 크기를 가진 텐서를 매 에포크마다 모델의 입력으로 사용\n",
        "\n",
        "    loss = criterion(outputs.view(-1, dic_size), Y.view(-1))\n",
        "    loss.backward()\n",
        "\n",
        "    optimizer.step()\n",
        "\n",
        "    # results의 텐서 크기는 (170, 10)\n",
        "    results = outputs.argmax(dim=2)\n",
        "\n",
        "    predict_str = str()\n",
        "\n",
        "    for j, result in enumerate(results) :\n",
        "        if j == 0: # 처음에는 예측 결과를 전부 가져오지만\n",
        "            predict_str += ''.join([char_set[t] for t in result])\n",
        "        else:\n",
        "            predict_str += char_set[result[-1]]\n",
        "\n",
        "    print(predict_str)"
      ],
      "metadata": {
        "id": "NWVYDQGAPZNI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Charseq 실습\n",
        "\n",
        "smaple = \" if you want you\"\n",
        "\n",
        "# 딕셔너리 만들기\n",
        "\n",
        "char_set = sorted(list(set(smaple)))\n",
        "char_dic = {c: i for i, c in enumerate(char_set)}\n",
        "dic_size = len(char_dic)\n",
        "\n",
        "print(char_dic)\n",
        "\n",
        "# 네트워크 하이퍼파라미터 설정\n",
        "\n",
        "hidden_size = dic_size # 은닉층 사이즈는 문자 집합 크기와 무관!!! 랜덤하게 사용 가능\n",
        "\n",
        "# 데이터 준비\n",
        "\n",
        "idx = [char_dic[c] for c in smaple]\n",
        "x_data = [idx[:-1]]\n",
        "\n",
        "print('x data : {}'.format(x_data))\n",
        "\n",
        "x_one_hot = [np.eye(dic_size)[x] for x in x_data]\n",
        "\n",
        "print('one-hot vector : {}'.format(x_one_hot))\n",
        "\n",
        "y_data = [idx[1:]]\n",
        "\n",
        "print('y data : {}'.format(y_data))"
      ],
      "metadata": {
        "id": "F7NfhG0HPZKq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# tensor casting\n",
        "\n",
        "X = torch.FloatTensor(x_one_hot)\n",
        "Y = torch.LongTensor(y_data)\n",
        "\n",
        "# RNN 선언\n",
        "\n",
        "rnn = nn.RNN(dic_size, hidden_size, batch_first=True)\n",
        "\n",
        "# Loss와 optimizer 정의\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(rnn.parameters(), lr)"
      ],
      "metadata": {
        "id": "2vlwLpmKffc_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 간단한 학습 코드\n",
        "\n",
        "epoch = 50\n",
        "\n",
        "for i in range(epoch):\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    outputs, _ = rnn(X)\n",
        "\n",
        "    loss = criterion(outputs.view(-1, dic_size), Y.view(-1))\n",
        "    loss.backward()\n",
        "\n",
        "    optimizer.step()\n",
        "\n",
        "    # 결과\n",
        "\n",
        "    results = outputs.data.numpy().argmax(axis=2)\n",
        "    predict_str = ''.join([char_set[c] for c in np.squeeze(results)])\n",
        "    print(i, \"loss : \", loss.item(), \"prediction : \", result, \"label : \", y_data, \"prediciton_str : \", result_str)"
      ],
      "metadata": {
        "id": "Iojyq_Gef6Jv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 📍 Char RNN으로 이름 분류하기\n",
        "- 데이터 주소 : https://download.pytorch.org/tutorial/data.zip"
      ],
      "metadata": {
        "id": "r4x3Xc1uhhWI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "import sys\n",
        "import os\n",
        "\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "8eyjM-_Dhwsr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- data/names/[language].txt이 18개 존재\n",
        "- 각 파일에는 한 줄에 하나의 이름이 적혀져 있음 -> 로마자로 되어 있음\n",
        "- UNICODE -> ASCII"
      ],
      "metadata": {
        "id": "cktdusIti5cd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from __future__ import unicode_literals, print_function, division\n",
        "from io import open\n",
        "\n",
        "import glob\n",
        "import os\n",
        "\n",
        "def findFiles(path):\n",
        "    return glob.glob(path)\n",
        "\n",
        "print(findFiles('/content/drive/My Drive/Colab Notebooks/Deep Learning/data/names/*.txt'))"
      ],
      "metadata": {
        "id": "UqZyJBkqinSA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import unicodedata\n",
        "import string\n",
        "\n",
        "all_letters = string.ascii_letters + \" .,;'\"\n",
        "n_letters = len(all_letters) # 57 => 26 + 26 + 5\n",
        "\n",
        "# 유니코드 문자열을 ASCII로 변환\n",
        "\n",
        "def unicode2Ascii(s):\n",
        "    return ''.join(\n",
        "        c for c in unicodedata.normalize('NFD', s)\n",
        "        if unicodedata.category(c) != 'Mn'\n",
        "        and c in all_letters\n",
        "    )\n",
        "\n",
        "print(unicode2Ascii('Ślusàrski'))"
      ],
      "metadata": {
        "id": "y4EHK1OwinPf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 이름 데이터 파일을 읽고 줄 단위로 분리 -> 데이터 셋 구축!!\n",
        "\n",
        "def readLines(filename) :\n",
        "    lines = open(filename, encoding='utf-8').read().strip().split('\\n')\n",
        "    return [unicode2Ascii(line) for line in lines]"
      ],
      "metadata": {
        "id": "96y3Ke1oinNX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "category_lines = dict()\n",
        "all_categories = list()\n",
        "\n",
        "for filename in findFiles('/content/drive/My Drive/Colab Notebooks/Deep Learning/data/names/*.txt'):\n",
        "    category = os.path.splitext(os.path.basename(filename))[0]\n",
        "    all_categories.append(category)\n",
        "    lines = readLines(filename)\n",
        "    category_lines[category] = lines\n",
        "\n",
        "n_categories = len(all_categories)\n",
        "\n",
        "print(all_categories)\n",
        "print(category_lines)"
      ],
      "metadata": {
        "id": "60U-bGOXinKy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 📌 각 category(언어)를 line(이름)에 매핑하는 dict인 category_lines 생성"
      ],
      "metadata": {
        "id": "1xOTr6JDpO1J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(category_lines['Korean'][5:10])"
      ],
      "metadata": {
        "id": "OMrutWNJpWcH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ✅ 이름을 텐서로 변경\n",
        "- 하나의 문자를 표현하기 위해 one-hot 벡터를 사용\n",
        "- 단어를 만들기 위해 one-hot 벡터들을 2차원 매트릭스로 만들어 주어야 합니다."
      ],
      "metadata": {
        "id": "uOVXbdTQppiG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# all_letters로 문자의 위치(인덱스) 찾기 => 'a' -> 0\n",
        "\n",
        "def letterToIndex(letter):\n",
        "    return all_letters.find(letter)\n",
        "\n",
        "# 문자 하나를 one-hot vector(1 * 문자 집합의 크기) 텐서로 변환하는 함수\n",
        "\n",
        "def letterToTensor(letter):\n",
        "    t = torch.zeros(1, n_letters) # n_letters : 문자 집합의 크기\n",
        "    t[0][letterToIndex(letter)] = 1\n",
        "    return t"
      ],
      "metadata": {
        "id": "DbfoxqVMpWZx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 이름을 <line_length * 1 n_letters> 로 바꿔주어야 함\n",
        "\n",
        "def nameToTensor(name) :\n",
        "    tensor = torch.zeros(len(name), 1, n_letters)\n",
        "    for n, letter in enumerate(name):\n",
        "        tensor[n][0][letterToIndex(letter)] = 1\n",
        "    return tensor"
      ],
      "metadata": {
        "id": "lm_oMkhGpWXa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(letterToTensor('J'))"
      ],
      "metadata": {
        "id": "YXptppQbpWVi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(nameToTensor('Jones').size())"
      ],
      "metadata": {
        "id": "XrNGZmcEpWSz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ✅ 모델 구현"
      ],
      "metadata": {
        "id": "o6QFfyKuG1_O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class RNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super(RNN, self).__init__()\n",
        "\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        self.i2h = nn.Linear(input_size, hidden_size) # M * N\n",
        "        self.h2h = nn.Linear(hidden_size, hidden_size) # N * N => (M * N) * (N * N) = (M * N)\n",
        "        self.h2o = nn.Linear(hidden_size, output_size) # N * P => (M * N) * (N * P) = (M * P)\n",
        "        self.softmax = nn.LogSoftmax(dim=1) # M * P\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        hidden = F.tanh(self.i2h(input) + self.h2h(hidden))\n",
        "        output = self.h2o(hidden)\n",
        "        output = self.softmax(self.h2o(hidden))\n",
        "\n",
        "        return output, hidden\n",
        "\n",
        "    def initHidden(self):\n",
        "        return torch.zeros(1, self.hidden_size)"
      ],
      "metadata": {
        "id": "t3woqqyOG13o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_hidden = 128\n",
        "rnn = RNN(n_letters, n_hidden, n_categories)"
      ],
      "metadata": {
        "id": "D9oF96TdG100"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input = letterToTensor('A')\n",
        "hidden = torch.zeros(1, n_hidden)\n",
        "\n",
        "output_l, next_hidden = rnn(input, hidden)\n",
        "\n",
        "print(output_l)"
      ],
      "metadata": {
        "id": "YACaNpC_G1yl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input = nameToTensor('Albert')\n",
        "hidden = torch.zeros(1, n_hidden)\n",
        "\n",
        "output_n, next_hidden = rnn(input[0], hidden)\n",
        "\n",
        "print(output_n)"
      ],
      "metadata": {
        "id": "9P9F7Ou6G1wP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ✅ 학습 준비\n",
        "- Hepler function을 선언하자\n",
        "- 네트워크에는 softmax layer가 들어가 있습니다!\n",
        "- FC layer의 마지막 출력층에 softmax 함수가 적용된다면 CELoss를 쓸 수 없다! -> NLL(Negative Log Likelihood) loss를 써야 함"
      ],
      "metadata": {
        "id": "cmZQA_t6Qq5K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Hepler function\n",
        "\n",
        "def categoryFromOutput(output):\n",
        "    top_n, top_i = output.topk(1)\n",
        "    category_i = top_i[0].item() # 텐서에서 정수 값으로 변경\n",
        "\n",
        "    return all_categories[category_i], category_i\n",
        "\n",
        "print(categoryFromOutput(output_l))"
      ],
      "metadata": {
        "id": "ZMyirzGOG1t4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "def randomChoice(l) :\n",
        "    return l[random.randint(0, len(l) - 1)]\n",
        "\n",
        "def randomTrainingExample():\n",
        "    category = randomChoice(all_categories)\n",
        "    name = randomChoice(category_lines[category])\n",
        "    category_tensor = torch.tensor([all_categories.index(category)], dtype=torch.long)\n",
        "    name_tensor = nameToTensor(name)\n",
        "\n",
        "    return category, name, category_tensor, name_tensor\n",
        "\n",
        "\n",
        "for _ in range(10):\n",
        "    category, name, category_tensor, name_tensor = randomTrainingExample()\n",
        "    print('category = ', category, '/ name = ', name)"
      ],
      "metadata": {
        "id": "Q5Dl9PoupV_8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ✅ 모델 학습\n",
        "- nn.CELoss => nn.NLLoss + Softmax()"
      ],
      "metadata": {
        "id": "fPupTirlV2yK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "critierion = nn.NLLLoss()"
      ],
      "metadata": {
        "id": "MCfHGP9cG1rM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lr = 0.005"
      ],
      "metadata": {
        "id": "weW-5jK6G1o3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(category_tensor, name_tensor):\n",
        "    hidden = rnn.initHidden()\n",
        "\n",
        "    rnn.zero_grad()\n",
        "\n",
        "    for i in range(name_tensor.size()[0]):\n",
        "        output, hidden = rnn(name_tensor[i], hidden)\n",
        "\n",
        "    loss = criterion(output, category_tensor)\n",
        "    loss.backward()\n",
        "\n",
        "    for p in rnn.parameters():\n",
        "        p.data.add_(p.grad.data, alpha=-lr)\n",
        "\n",
        "    return output, loss.item()"
      ],
      "metadata": {
        "id": "sqwYcEWqG1jz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import math\n",
        "\n",
        "n_iters = 100000\n",
        "print_every = 5000\n",
        "plot_every = 1000\n",
        "\n",
        "# 시각화를 위한 loss 추적\n",
        "current_loss = 0\n",
        "all_losses = []\n",
        "\n",
        "def timeSince(since):\n",
        "    now = time.time()\n",
        "    s = now - since\n",
        "    m = math.floor(s / 60)\n",
        "    s -= m * 60\n",
        "    return '%dm %ds' % (m, s)\n",
        "\n",
        "start = time.time()\n",
        "\n",
        "for iter in range(1, n_iters + 1):\n",
        "    category, line, category_tensor, line_tensor = randomTrainingExample()\n",
        "    output, loss = train(category_tensor, line_tensor)\n",
        "    current_loss += loss\n",
        "\n",
        "    if iter % print_every == 0:\n",
        "        guess, guess_i = categoryFromOutput(output)\n",
        "        correct = '✓' if guess == category else '✗ (%s)' % category\n",
        "        print('%d %d%% (%s) %.4f %s / %s %s' % (iter, iter / n_iters * 100, timeSince(start), loss, line, guess, correct))\n",
        "\n",
        "    # 현재 평균 loss을 전체 loss 리스트에 추가\n",
        "    if iter % plot_every == 0:\n",
        "        all_losses.append(current_loss / plot_every)\n",
        "        current_loss = 0"
      ],
      "metadata": {
        "id": "ZlkEJ-nHbYeP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(all_losses)"
      ],
      "metadata": {
        "id": "hRiXjmFtbYcC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ✅ Confusion Matrix\n",
        "\n",
        "- Row가 label, Column이 prediction\n",
        "- 실제 언어가 네트워크에서 어떤 언어로 추론이 되는지를 확인하기 위한 혼란, 혼돈 행렬"
      ],
      "metadata": {
        "id": "uVX0LcjDi4b_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "confusion = torch.zeros(n_categories, n_categories)\n",
        "n_conf = 10000\n",
        "\n",
        "def evaluate(name_tensor):\n",
        "    hidden = rnn.initHidden()\n",
        "\n",
        "    for i in range(name_tensor.size()[0]):\n",
        "        output, hidden = rnn(name_tensor[i], hidden)\n",
        "\n",
        "    return output"
      ],
      "metadata": {
        "id": "cKaYGBSubYZj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(n_conf):\n",
        "    category, line, category_tensor, name_tensor = randomTrainingExample()\n",
        "    output = evaluate(name_tensor)\n",
        "    guess, guess_i = categoryFromOutput(output)\n",
        "    category_i = all_categories.index(category)\n",
        "    confusion[category_i][guess_i] += 1\n",
        "\n",
        "for i in range(n_categories):\n",
        "    confusion[i] = confusion[i] / confusion[i].sum()\n",
        "\n",
        "\n",
        "fig = plt.figure()\n",
        "ax = fig.add_subplot(111)\n",
        "cax = ax.matshow(confusion.numpy())\n",
        "fig.colorbar(cax)\n",
        "\n",
        "ax.set_xticklabels([''] + all_categories, rotation=90)\n",
        "ax.set_yticklabels([''] + all_categories)\n",
        "\n",
        "ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "1_SazHrGbYW9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(input_line, n_predictions=3):\n",
        "    print('\\n> %s' % input_line)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        output = evaluate(nameToTensor(input_line))\n",
        "\n",
        "        # TopK prediciton\n",
        "        topv, topi = output.topk(n_predictions, 1, True)\n",
        "        predictions = list()\n",
        "\n",
        "        for i in range(n_predictions):\n",
        "            value = topv[0][i].item()\n",
        "            category_index = topi[0][i].item()\n",
        "            print('(%.2f) %s' % (value, all_categories[category_index]))\n",
        "            predictions.append([value, all_categories[category_index]])\n",
        "\n",
        "predict('Mo')"
      ],
      "metadata": {
        "id": "kefQv1R4rDzo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}